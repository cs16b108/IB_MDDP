{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "IB_Diarization_New.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cs16b108/IB_MDDP/blob/master/IB_Diarization_New.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D5jANRDmEMlV",
        "outputId": "13d0701f-04d0-4d37-d89a-d5c2a2550ab7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A2xzt9uJrsZF",
        "outputId": "2cda062d-7f9c-4e03-eca4-12ccf4685a75",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 546
        }
      },
      "source": [
        "!pip install webrtcvad\n",
        "!pip install --upgrade --user hmmlearn\n",
        "!pip install python_speech_features\n",
        "!pip install xml"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting webrtcvad\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/89/34/e2de2d97f3288512b9ea56f92e7452f8207eb5a0096500badf9dfd48f5e6/webrtcvad-2.0.10.tar.gz (66kB)\n",
            "\r\u001b[K     |█████                           | 10kB 15.4MB/s eta 0:00:01\r\u001b[K     |██████████                      | 20kB 2.1MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 30kB 2.5MB/s eta 0:00:01\r\u001b[K     |███████████████████▉            | 40kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 51kB 2.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 61kB 2.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 71kB 2.3MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: webrtcvad\n",
            "  Building wheel for webrtcvad (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for webrtcvad: filename=webrtcvad-2.0.10-cp36-cp36m-linux_x86_64.whl size=71359 sha256=e09ac8fe66e2274a9ca4d9951c9cfc206f0e692fd1439f5968990dbc3b47b53f\n",
            "  Stored in directory: /root/.cache/pip/wheels/44/2a/18/bd1aec41cac7c3051fe95d92a6ed446122ea31dc713c432fa1\n",
            "Successfully built webrtcvad\n",
            "Installing collected packages: webrtcvad\n",
            "Successfully installed webrtcvad-2.0.10\n",
            "Collecting hmmlearn\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b3/49/9e9a89cee24b26ef6afec5abbd5eb9cf14632855f32b999389873ecb1b4e/hmmlearn-0.2.4-cp36-cp36m-manylinux1_x86_64.whl (361kB)\n",
            "\u001b[K     |████████████████████████████████| 368kB 3.4MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: scikit-learn>=0.16 in /usr/local/lib/python3.6/dist-packages (from hmmlearn) (0.22.2.post1)\n",
            "Requirement already satisfied, skipping upgrade: scipy>=0.19 in /usr/local/lib/python3.6/dist-packages (from hmmlearn) (1.4.1)\n",
            "Requirement already satisfied, skipping upgrade: numpy>=1.10 in /usr/local/lib/python3.6/dist-packages (from hmmlearn) (1.18.5)\n",
            "Requirement already satisfied, skipping upgrade: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.16->hmmlearn) (0.16.0)\n",
            "Installing collected packages: hmmlearn\n",
            "Successfully installed hmmlearn-0.2.4\n",
            "Collecting python_speech_features\n",
            "  Downloading https://files.pythonhosted.org/packages/ff/d1/94c59e20a2631985fbd2124c45177abaa9e0a4eee8ba8a305aa26fc02a8e/python_speech_features-0.6.tar.gz\n",
            "Building wheels for collected packages: python-speech-features\n",
            "  Building wheel for python-speech-features (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for python-speech-features: filename=python_speech_features-0.6-cp36-none-any.whl size=5887 sha256=f0f838c055baff302375df9b2c4c0684f13f9431c45773f00b2488d088f97e7f\n",
            "  Stored in directory: /root/.cache/pip/wheels/3c/42/7c/f60e9d1b40015cd69b213ad90f7c18a9264cd745b9888134be\n",
            "Successfully built python-speech-features\n",
            "Installing collected packages: python-speech-features\n",
            "Successfully installed python-speech-features-0.6\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h4zv8xRTrsZU"
      },
      "source": [
        "import os\n",
        "from os.path import isfile, isdir, join\n",
        "from pathlib import Path\n",
        "import math\n",
        "import numpy as np\n",
        "# import numpy as np\n",
        "import random\n",
        "# import math\n",
        "from scipy.stats import multivariate_normal\n",
        "from matplotlib import pyplot as plt\n",
        "from scipy.spatial import distance\n",
        "import scipy.io.wavfile as wav\n",
        "from python_speech_features import mfcc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DHCZqd13rsZW"
      },
      "source": [
        "########################################################\n",
        "############## Read WAV and perform VAD ################\n",
        "## Already done once and files stored on google drive ##\n",
        "########################################################\n",
        "\n",
        "# import collections\n",
        "# import contextlib\n",
        "# import sys\n",
        "# import wave\n",
        "# import webrtcvad\n",
        "\n",
        "\n",
        "# def read_wave(path):\n",
        "#     \"\"\"Reads a .wav file.\n",
        "#     Takes the path, and returns (PCM audio data, sample rate).\n",
        "#     \"\"\"\n",
        "#     with contextlib.closing(wave.open(path, 'rb')) as wf:\n",
        "#         num_channels = wf.getnchannels()\n",
        "#         assert num_channels == 1\n",
        "#         sample_width = wf.getsampwidth()\n",
        "#         assert sample_width == 2\n",
        "#         sample_rate = wf.getframerate()\n",
        "#         assert sample_rate in (8000, 16000, 32000, 48000)\n",
        "#         pcm_data = wf.readframes(wf.getnframes())\n",
        "#         return pcm_data, sample_rate\n",
        "\n",
        "\n",
        "# def write_wave(path, audio, sample_rate):\n",
        "#     \"\"\"Writes a .wav file.\n",
        "#     Takes path, PCM audio data, and sample rate.\n",
        "#     \"\"\"\n",
        "#     with contextlib.closing(wave.open(path, 'wb')) as wf:\n",
        "#         wf.setnchannels(1)\n",
        "#         wf.setsampwidth(2)\n",
        "#         wf.setframerate(sample_rate)\n",
        "#         wf.writeframes(audio)\n",
        "\n",
        "\n",
        "# class Frame(object):\n",
        "#     \"\"\"Represents a \"frame\" of audio data.\"\"\"\n",
        "#     def __init__(self, bytes, timestamp, duration):\n",
        "#         self.bytes = bytes\n",
        "#         self.timestamp = timestamp\n",
        "#         self.duration = duration\n",
        "\n",
        "\n",
        "# def frame_generator(frame_duration_ms, audio, sample_rate):\n",
        "#     \"\"\"Generates audio frames from PCM audio data.\n",
        "#     Takes the desired frame duration in milliseconds, the PCM data, and\n",
        "#     the sample rate.\n",
        "#     Yields Frames of the requested duration.\n",
        "#     \"\"\"\n",
        "#     n = int(sample_rate * (frame_duration_ms / 1000.0) * 2)\n",
        "#     offset = 0\n",
        "#     timestamp = 0.0\n",
        "#     duration = (float(n) / sample_rate) / 2.0\n",
        "#     while offset + n < len(audio):\n",
        "#         yield Frame(audio[offset:offset + n], timestamp, duration)\n",
        "#         timestamp += duration\n",
        "#         offset += n\n",
        "\n",
        "\n",
        "# def vad_collector(sample_rate, frame_duration_ms,\n",
        "#                   padding_duration_ms, vad, frames,vuv_frames):\n",
        "#     \"\"\"Filters out non-voiced audio frames.\n",
        "#     Given a webrtcvad.Vad and a source of audio frames, yields only\n",
        "#     the voiced audio.\n",
        "#     Uses a padded, sliding window algorithm over the audio frames.\n",
        "#     When more than 90% of the frames in the window are voiced (as\n",
        "#     reported by the VAD), the collector triggers and begins yielding\n",
        "#     audio frames. Then the collector waits until 90% of the frames in\n",
        "#     the window are unvoiced to detrigger.\n",
        "#     The window is padded at the front and back to provide a small\n",
        "#     amount of silence or the beginnings/endings of speech around the\n",
        "#     voiced frames.\n",
        "#     Arguments:\n",
        "#     sample_rate - The audio sample rate, in Hz.\n",
        "#     frame_duration_ms - The frame duration in milliseconds.\n",
        "#     padding_duration_ms - The amount to pad the window, in milliseconds.\n",
        "#     vad - An instance of webrtcvad.Vad.\n",
        "#     frames - a source of audio frames (sequence or generator).\n",
        "#     Returns: A generator that yields PCM audio data.\n",
        "#     \"\"\"\n",
        "#     num_padding_frames = int(padding_duration_ms / frame_duration_ms)\n",
        "#     # We use a deque for our sliding window/ring buffer.\n",
        "#     ring_buffer = collections.deque(maxlen=num_padding_frames)\n",
        "#     # We have two states: TRIGGERED and NOTTRIGGERED. We start in the\n",
        "#     # NOTTRIGGERED state.\n",
        "#     triggered = False\n",
        "\n",
        "#     index=-1\n",
        "#     voiced_frames = []\n",
        "#     for frame in frames:\n",
        "\n",
        "#         index+=1\n",
        "#         is_speech = vad.is_speech(frame.bytes, sample_rate)\n",
        "\n",
        "#         sys.stdout.write('1' if is_speech else '0')\n",
        "#         if not triggered:\n",
        "#             ring_buffer.append((frame, is_speech))\n",
        "#             num_voiced = len([f for f, speech in ring_buffer if speech])\n",
        "#             # If we're NOTTRIGGERED and more than 90% of the frames in\n",
        "#             # the ring buffer are voiced frames, then enter the\n",
        "#             # TRIGGERED state.\n",
        "#             if num_voiced > 0.9 * ring_buffer.maxlen:\n",
        "#                 triggered = True\n",
        "#                 sys.stdout.write('+(%s)' % (ring_buffer[0][0].timestamp,))\n",
        "#                 # We want to yield all the audio we see from now until\n",
        "#                 # we are NOTTRIGGERED, but we have to start with the\n",
        "#                 # audio that's already in the ring buffer.\n",
        "\n",
        "#                 id = 0 #we must start actually with num_padding_frames-1 and do index-- \n",
        "#                 for f, s in ring_buffer:\n",
        "#                     voiced_frames.append(f)\n",
        "#                     vuv_frames[index-id]=1\n",
        "#                     id+=1\n",
        "\n",
        "#                 ring_buffer.clear()\n",
        "#         else:\n",
        "#             # We're in the TRIGGERED state, so collect the audio data\n",
        "#             # and add it to the ring buffer.\n",
        "#             voiced_frames.append(frame)\n",
        "#             vuv_frames[index] = 1\n",
        "#             ring_buffer.append((frame, is_speech))\n",
        "#             num_unvoiced = len([f for f, speech in ring_buffer if not speech])\n",
        "#             # If more than 90% of the frames in the ring buffer are\n",
        "#             # unvoiced, then enter NOTTRIGGERED and yield whatever\n",
        "#             # audio we've collected.\n",
        "#             if num_unvoiced > 0.9 * ring_buffer.maxlen:\n",
        "#                 sys.stdout.write('-(%s)' % (frame.timestamp + frame.duration))\n",
        "#                 triggered = False\n",
        "#                 yield b''.join([f.bytes for f in voiced_frames])\n",
        "#                 ring_buffer.clear()\n",
        "#                 voiced_frames = []\n",
        "#     if triggered:\n",
        "#         sys.stdout.write('-(%s)' % (frame.timestamp + frame.duration))\n",
        "#     sys.stdout.write('\\n')\n",
        "#     # If we have any leftover voiced audio when we run out of input,\n",
        "#     # yield it.\n",
        "#     if voiced_frames:\n",
        "#         yield b''.join([f.bytes for f in voiced_frames])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "na0eIG-qrsZY"
      },
      "source": [
        "# def main():\n",
        "#     # if len(args) != 2:\n",
        "#     #     sys.stderr.write(\n",
        "#     #         'Usage: silenceremove.py <aggressiveness> <path to wav file>\\n')\n",
        "#     #     sys.exit(1)\n",
        "#     path = '/content/amicorpus/'\n",
        "#     dir_list = sorted(os.listdir(path))\n",
        "#     cnt = 0\n",
        "#     for d in dir_list:\n",
        "#       dir_name = join(path,d)\n",
        "#       if isdir(dir_name):\n",
        "#         filePath = join(path, d, 'audio', d+'.Mix-Headset.wav')\n",
        "#         try:\n",
        "#           audio, sample_rate = read_wave(filePath)\n",
        "#           vad = webrtcvad.Vad(int(1))\n",
        "#           frames = frame_generator(30, audio, sample_rate)\n",
        "#           frames = list(frames)\n",
        "#           nof_frames = 1+(len(audio)-1)/int(sample_rate * (frame_duration_ms / 1000.0) * 2)\n",
        "#           vuv_frames = np.zeros((nof_frames],)) \n",
        "#           segments = vad_collector(sample_rate, 30, 300, vad, frames,vuv_frames)\n",
        "\n",
        "#           # Segmenting the Voice audio and save it in list as bytes\n",
        "#           concataudio = [segment for segment in segments]\n",
        "\n",
        "#           joinedaudio = b\"\".join(concataudio)\n",
        "#           writePath = join('/content/drive/My Drive/IB_Diarization/amicorpus_non_silence', d, 'audio')\n",
        "#           Path(writePath).mkdir(parents=True, exist_ok=True)\n",
        "#           write_wave(join(writePath, d+'.Mix-Headset.wav'), joinedaudio, sample_rate)\n",
        "#           cnt += 1\n",
        "#           # if(cnt == 2):\n",
        "#           #   break\n",
        "#         except:\n",
        "#           print(\"Skipping: \", filePath)\n",
        "#     print(\"Converted: \",cnt)\n",
        "# if __name__ == '__main__':\n",
        "#     main()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mR0Yhd0OrsZb"
      },
      "source": [
        "# rm -rf amicorpus_non_silence/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LqNiYH1QrsZd"
      },
      "source": [
        "# !chmod 755 amiBuild-13720-Mon-Aug-31-2020.wget.sh"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9euMwS6NrsZf"
      },
      "source": [
        "# !ls -l '/content/drive/My Drive/amicorpus_non_silence' | wc -l"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C8RJQMUbrsZh"
      },
      "source": [
        "# !./amiBuild-13720-Mon-Aug-31-2020.wget.sh"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n0k0Zr8IrsZj"
      },
      "source": [
        "# !tar -czvf filename.tar.gz amicorpus"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oR1tYAM5rsZl"
      },
      "source": [
        "# !cp filename.tar.gz /content/drive/My\\ Drive/amicorpus.tar.gz"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fZIAuddBrsZn"
      },
      "source": [
        "# !tar -xzvf /content/drive/My\\ Drive/amicorpus.tar.gz"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9SQrCOiIrsZp"
      },
      "source": [
        "# !./ComputeFeatures mfcc.config /content/drive/My\\ Drive/amicorpus_non_silence/ES2002b/audio/ES2002b.Mix-Headset.wav frameCepstrum+frameDeltaCepstrum sa1.mfcc 0.06 A"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FuIsCQE6rsZs"
      },
      "source": [
        "# !chmod 755 ComputeFeatures"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LHq9U1yQrsZv"
      },
      "source": [
        "# !chmod 755 mfcc.config"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZePchLWDrsZx"
      },
      "source": [
        "####################################\n",
        "### Actual Code Starts from Here ###\n",
        "####################################"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mMQYh3vgFXzO",
        "outputId": "c8bf15fd-d2db-4de1-e2bd-4536b5adf3c6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "%cd '/content/drive/My Drive/IB_Diarization/amicorpus_non_silence/ES2002b/audio/'\n",
        "!ls\n",
        "%cd /content"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/IB_Diarization/amicorpus_non_silence/ES2002b/audio\n",
            "ES2002b.Mix-Headset.wav\n",
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ekr76KGrsZ0"
      },
      "source": [
        "#Define path to wav files created after VAD\n",
        "path = '/content/drive/My Drive/IB_Diarization/amicorpus_non_silence/'\n",
        "\n",
        "overlap = 0.01 #10 ms window shift\n",
        "fullPath = join(path,'ES2002b/audio/ES2002b.Mix-Headset.wav')\n",
        "(rate,sig) = wav.read(fullPath)\n",
        "mfcc_feat = mfcc(sig, rate, numcep = 19, nfilt = 26, winlen=0.03, winstep=overlap)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tA4XNF2XxeAx"
      },
      "source": [
        "n, d = mfcc_feat.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NYpv2WHys4m6"
      },
      "source": [
        "# overlap = 0.01 #10 ms window shift\n",
        "init_cluster_time = 2500 #2.5sec\n",
        "init_cluster_len = math.ceil(init_cluster_time/(overlap*1000))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fttKNb7UtQ7z"
      },
      "source": [
        "num_of_clusters = math.ceil(n/init_cluster_len)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t_AYZWAdxN_U",
        "outputId": "8551297b-87b0-4598-d6ee-2dbd82d04e1d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "num_of_clusters"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "812"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wlH4hUMdxnkA"
      },
      "source": [
        "t = np.array_split(mfcc_feat, 3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B2qzsMekx04_"
      },
      "source": [
        "class GMM:\n",
        "    def __init__(self, num_of_clusters):\n",
        "        self.num_of_clusters = num_of_clusters\n",
        "        self.log_likelihood =[]\n",
        "        self.LL_diff = []\n",
        "        # self.num_of_speakers = num_of_speakers\n",
        "\n",
        "    def gaussian_prob(self, x, mean, sigma):\n",
        "        d = x.shape[0]\n",
        "        p = ((2*math.pi)**(-d/2))*(np.linalg.det(sigma)**(-0.5))*np.exp(-0.5*(x-mean).reshape(d,1).T.dot(np.linalg.inv(sigma)).dot((x-mean).reshape(d,1)))\n",
        "        return p\n",
        "\n",
        "    def k_means(self, X):\n",
        "        n = X.shape[0]\n",
        "        d = X.shape[1]\n",
        "        itr = 0\n",
        "        #self.centroid = np.zeros((self.num_of_clusters, d), dtype = 'float64')\n",
        "        self.centroids = X[random.sample(range(n), self.num_of_clusters)]\n",
        "        self.cluster_assigned = np.zeros(n, dtype = int)\n",
        "        error = 0.0\n",
        "        while True:\n",
        "            print(\"Now at itr - \", itr)\n",
        "            # print(\"Centroids - \", self.centroids)\n",
        "            for i in range(n):\n",
        "                f_vec = X[i]\n",
        "                dist = np.sqrt(np.sum((f_vec-self.centroids)**2, 1))\n",
        "                # print(\"Dist Shape is - \", dist.shape)\n",
        "                self.cluster_assigned[i] = np.argmin(dist)\n",
        "            new_error = np.sum(np.sqrt(np.sum((X - self.centroids[self.cluster_assigned])**2, 1)))\n",
        "            if(itr>0):\n",
        "                print(\"Error Difference is - \", np.abs(error-new_error))\n",
        "            new_centroids = np.zeros((self.num_of_clusters, d), dtype = 'float64')\n",
        "            count_of_elements = np.zeros(self.num_of_clusters, dtype = int)\n",
        "            for i in range(n):\n",
        "                c_ind = self.cluster_assigned[i]\n",
        "                new_centroids[c_ind] += X[i]\n",
        "                count_of_elements[c_ind] += 1\n",
        "            new_centroids = new_centroids/count_of_elements[:,None]\n",
        "            if np.abs(new_error-error)<10 or np.array_equal(self.centroids, new_centroids) or itr>=5:\n",
        "                print(\"Breaking at itr - \", itr)\n",
        "                break\n",
        "            else:\n",
        "                self.centroids = np.copy(new_centroids)\n",
        "            itr += 1\n",
        "            error = new_error\n",
        "\n",
        "    def EM_GMM_INBUILT(self, X):\n",
        "        N = X.shape[0]\n",
        "        d = X.shape[1]\n",
        "        from sklearn.mixture import GaussianMixture as GMM\n",
        "        g = GMM(n_components=64, covariance_type = 'full', max_iter = 1)\n",
        "        g.fit(X)\n",
        "        print(\"Created\")\n",
        "\n",
        "    def EM_GMM(self, X):\n",
        "        N = X.shape[0]\n",
        "        d = X.shape[1]\n",
        "        self.cov_mat = np.zeros((self.num_of_clusters, d, d), dtype = 'float64')\n",
        "        self.gamma = np.zeros((N,self.num_of_clusters), dtype = 'float64')\n",
        "        likelihood = np.zeros((N,self.num_of_clusters), dtype = 'float64')\n",
        "        self.pi_prob = np.zeros(self.num_of_clusters, dtype = 'float64')\n",
        "        self.Nk = np.zeros(self.num_of_clusters, dtype = 'float64')\n",
        "        for k in range(self.num_of_clusters):\n",
        "            indices = (np.argwhere(self.cluster_assigned==k)).ravel()\n",
        "            X_k = X[indices]\n",
        "            X_k_centered = X_k - self.centroids[k]\n",
        "            self.Nk[k] = X_k.shape[0]\n",
        "            # print(\"Xk \",X_k.shape)\n",
        "            # print(\"Xkc \",X_k_centered.shape)\n",
        "            # print(\"cov mat \",self.cov_mat[k])\n",
        "            self.cov_mat[k] = (1/self.Nk[k])*(X_k_centered.T.dot(X_k_centered))\n",
        "        # print(self.Nk)\n",
        "        self.pi_prob = self.Nk/N\n",
        "        print(\"EM Begins\")\n",
        "        itr = 1\n",
        "        prev_log_likelihood = 0.0\n",
        "        \n",
        "        while True:\n",
        "            #####################################\n",
        "            ############   E Step   #############\n",
        "            #####################################\n",
        "            for k in range(self.num_of_clusters):\n",
        "                #self.gamma[i,k] = self.gaussian_prob(X[i], self.centroids[k], self.cov_mat[k])\n",
        "                self.cov_mat[k] += 1e-6*np.identity(d)\n",
        "                likelihood[:,k] =  multivariate_normal.pdf(X, self.centroids[k], self.cov_mat[k]).ravel()\n",
        "                # print(\"Done \", k)\n",
        "            # log_likelihood = np.sum(np.sum((likelihood*self.pi_prob), axis = 1))\n",
        "\n",
        "            # for i in range(N):\n",
        "            #     print(\"Done \",i)\n",
        "             \n",
        "            self.gamma = likelihood*self.pi_prob\n",
        "            self.gamma = self.gamma/(np.sum(self.gamma, axis = 1)[:,None])\n",
        "            # print(\"E done\")\n",
        "\n",
        "            #####################################\n",
        "            ############   M Step   #############\n",
        "            #####################################\n",
        "            self.Nk = np.sum(self.gamma, axis = 0)\n",
        "            self.pi_prob = self.Nk/N\n",
        "            for k in range(self.num_of_clusters):\n",
        "                self.centroids[k] = (1/self.Nk[k])*np.sum((X*self.gamma[:,k][:,np.newaxis]), axis = 0)\n",
        "                X_centered = X - self.centroids[k]\n",
        "                self.cov_mat[k] = (1/self.Nk[k])*((X_centered*self.gamma[:,k][:,np.newaxis]).T.dot(X_centered))\n",
        "            # print(\"M done\")\n",
        "\n",
        "            #####################################\n",
        "            ########   Log Likelihood   #########\n",
        "            #####################################\n",
        "            new_log_likelihood = np.sum(np.log(np.sum((likelihood*self.pi_prob), axis = 1)))\n",
        "            self.log_likelihood.append(new_log_likelihood)\n",
        "            diff_LL = np.abs(new_log_likelihood-prev_log_likelihood)\n",
        "            self.LL_diff.append(diff_LL)\n",
        "            print(\"Itr = \", itr, \" Current LL is - \",new_log_likelihood)\n",
        "            print(\"Change In LL is - \",diff_LL)\n",
        "            if(diff_LL<100 or itr>=10):\n",
        "                print(\"EM Finished at iteration - \", itr)\n",
        "                break\n",
        "            itr += 1\n",
        "            prev_log_likelihood = new_log_likelihood"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T0j7BniJyGT-",
        "outputId": "8fbc0af6-d3b9-44fb-c198-2e67ab150ae0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 635
        }
      },
      "source": [
        "# ug = GMM(num_of_clusters)\n",
        "# ug.k_means(mfcc_feat)\n",
        "# ug.EM_GMM(mfcc_feat)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Now at itr -  0\n",
            "Now at itr -  1\n",
            "Error Difference is -  599823.8919972638\n",
            "Now at itr -  2\n",
            "Error Difference is -  101588.37360343058\n",
            "Now at itr -  3\n",
            "Error Difference is -  44667.57336829975\n",
            "Now at itr -  4\n",
            "Error Difference is -  26511.08849777747\n",
            "Now at itr -  5\n",
            "Error Difference is -  17676.367046424188\n",
            "Breaking at itr -  5\n",
            "EM Begins\n",
            "Itr =  1  Current LL is -  -12456942.269188596\n",
            "Change In LL is -  12456942.269188596\n",
            "Itr =  2  Current LL is -  -12360672.840190332\n",
            "Change In LL is -  96269.42899826355\n",
            "Itr =  3  Current LL is -  -12316483.910872726\n",
            "Change In LL is -  44188.92931760661\n",
            "Itr =  4  Current LL is -  -12289174.049058296\n",
            "Change In LL is -  27309.861814429983\n",
            "Itr =  5  Current LL is -  -12270557.120972758\n",
            "Change In LL is -  18616.928085537627\n",
            "Itr =  6  Current LL is -  -12257349.86940295\n",
            "Change In LL is -  13207.25156980753\n",
            "Itr =  7  Current LL is -  -12247281.898067242\n",
            "Change In LL is -  10067.971335709095\n",
            "Itr =  8  Current LL is -  -12239313.845844803\n",
            "Change In LL is -  7968.052222438157\n",
            "Itr =  9  Current LL is -  -12232856.838453976\n",
            "Change In LL is -  6457.0073908269405\n",
            "Itr =  10  Current LL is -  -12227514.011712547\n",
            "Change In LL is -  5342.826741429046\n",
            "EM Finished at iteration -  10\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ihYpZGpIY5WX"
      },
      "source": [
        "def fitUnimodal(C):\n",
        "  means = []\n",
        "  covMatrices = []\n",
        "  for c in C:\n",
        "    means.append(np.mean(c, axis = 0))\n",
        "    covMatrices.append(np.cov(c.T))\n",
        "  return means, covMatrices"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O54Lqzff0zce"
      },
      "source": [
        "def calc_prob(x, GaussianMeans, GaussianCovMatrices):\n",
        "  p = 0.0\n",
        "  D = x.shape[0]\n",
        "  numOfClusters = len(GaussianMeans)\n",
        "  for i in range(D):\n",
        "    s = x[i]\n",
        "    for k in range(numOfClusters):\n",
        "    #self.gamma[i,k] = self.gaussian_prob(X[i], self.centroids[k], self.cov_mat[k])\n",
        "      cov_matrix = 1e-6*np.identity(d) + GaussianCovMatrices[k]\n",
        "      # cov_matrix = \n",
        "      p =  p + ug.pi_prob[k]*multivariate_normal.pdf(s, ug.centroids[k], cov_matrix)\n",
        "  p = p/D\n",
        "  return p"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Y7msXyWJkMH"
      },
      "source": [
        "def calcYgivenX(x, GaussianMeans, GaussianCovMatrices, i):\n",
        "  p = 0.0\n",
        "  numOfClusters = len(GaussianMeans)\n",
        "  w = 1.0/numOfClusters\n",
        "  D = x.shape[0]\n",
        "  probMat = np.zeros((D, num_of_clusters), dtype = float)\n",
        "  for i in range(num_of_clusters):\n",
        "    probMat[:,i] = multivariate_normal(x, GaussianMeans[i], GaussianCovMatrices[i])\n",
        "  p = 0.0\n",
        "  self.gamma = self.gamma/(np.sum(self.gamma, axis = 1)[:,None]) \n",
        "  return p"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wUZLV2W5RKZo"
      },
      "source": [
        "########################\n",
        "##### IB Algorithm #####\n",
        "########################\n",
        "\n",
        "#Init Variables\n",
        "N = num_of_clusters\n",
        "C = np.array_split(mfcc_feat, num_of_clusters)\n",
        "GaussianMeans, GaussianCovMatrices = fitUnimodal(C)\n",
        "ClusterMapping = dict(zip(range(num_of_clusters), [[i] for i in range(num_of_clusters)]))\n",
        "probC = []\n",
        "for i in range(N):\n",
        "  p = 0.0\n",
        "  D = C[i].shape[0]\n",
        "  for j in range(D):\n",
        "    s = C[i][j]\n",
        "    p += multivariate_normal.pdf(s, GaussianMeans[i], GaussianCovMatrices[i])\n",
        "  p = p/D \n",
        "  probC.append(p)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FQejbER_OfF9"
      },
      "source": [
        "probX = probC.copy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tfyeSjbwyHgY",
        "outputId": "dbe356ad-a810-44f4-be13-7b4a082cb7dc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 181
        }
      },
      "source": [
        "probYgivenC = []\n",
        "probCgivenX = []\n",
        "for i in range(N):\n",
        "  temp1 = []\n",
        "  temp2 = []\n",
        "  x = C[i]\n",
        "  w = 1.0/num_of_clusters\n",
        "  D = x.shape[0]\n",
        "  probMat = np.zeros((D, num_of_clusters), dtype = float)\n",
        "  for j in range(num_of_clusters):\n",
        "    probMat[:,j] = multivariate_normal.pdf(x, GaussianMeans[j], GaussianCovMatrices[j]).ravel()\n",
        "  probMat = probMat/(np.sum(probMat, axis = 1)[:,None])\n",
        "  temp1 = np.mean(probMat, axis = 0)\n",
        "  for j in range(N):\n",
        "    # p = probMat[i,j]/(np.sum(probMat[i,j], axis = 1)[:,None])\n",
        "    # p = calcYgivenX(x, GaussianMeans, GaussianCovMatrices, i)\n",
        "    # temp1.append(p)\n",
        "    if j == i:\n",
        "      temp2.append(1.0)\n",
        "    else:\n",
        "      temp2.append(0.0)\n",
        "    # print(\"Done2 \",j)\n",
        "  probYgivenC.append(temp1)\n",
        "  probCgivenX.append(temp2)\n",
        "  if i%100 == 0:\n",
        "    print(\"Done \",i)\n",
        "\n",
        "# # prob_cond_y_c = np.zeros((N, N), dtype = float)\n",
        "# # prob_cond_c_x = np.zeros((N, N), dtype = float)\n",
        "# del_F = np.zeros((N, N), dtype = float)\n",
        "# for i in range(N):\n",
        "#   prob_c(i) = calc_prob(C[i], ug)\n",
        "#   for j in range(N):\n",
        "#     prob_cond_y_c[j][i] = calc_cond_prob(j, C[i], ug)\n",
        "#     if(j == i):\n",
        "#       prob_cond_c_x[j][i] = 1\n",
        "\n",
        "\n",
        "\n",
        "#Main Algo\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Done  0\n",
            "Done  100\n",
            "Done  200\n",
            "Done  300\n",
            "Done  400\n",
            "Done  500\n",
            "Done  600\n",
            "Done  700\n",
            "Done  800\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fy1GaieALLwB",
        "outputId": "f076ef57-9a74-4bb6-862f-bc94383c37b4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        }
      },
      "source": [
        "beta = 10.0\n",
        "del_F = np.zeros((N, N), dtype = float)\n",
        "del_F[:,:] = np.inf\n",
        "probXgivenC = ((np.array(probCgivenX)*np.array(probX)).T/probC).T\n",
        "for i in range(N):\n",
        "  for j in range(i+1, N): \n",
        "    temp1 = distance.jensenshannon(np.array(probYgivenC)[:,i], np.array(probYgivenC)[:,j]) \n",
        "    temp2 = distance.jensenshannon(probXgivenC[i], probXgivenC[j]) \n",
        "    dij = temp1 - (1/beta)*temp2\n",
        "    del_F[i][j] = (probC[i] + probC[j])*dij\n",
        "    # del_F[i][j] = cal_objective_diff(C[i], C[j])\n",
        "  if i%100 == 0:\n",
        "    print(\"Done \",i)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Done  0\n",
            "Done  100\n",
            "Done  200\n",
            "Done  300\n",
            "Done  400\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3UBnkJ0-Bgl5"
      },
      "source": [
        "import pickle\n",
        "file_name = \"probYgivenC.sav\"\n",
        "pickle.dump(probYgivenC, open(file_name, 'wb'))\n",
        "file_name = \"probCgivenX.sav\"\n",
        "pickle.dump(probCgivenX, open(file_name, 'wb'))\n",
        "file_name = \"del_F.sav\"\n",
        "pickle.dump(del_F, open(file_name, 'wb'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lAcZYLCvL-By"
      },
      "source": [
        "# file_name = \"probYgivenC.sav\"\n",
        "# probYgivenC = pickle.load(open(file_name, 'rb'))\n",
        "# file_name = \"probCgivenX.sav\"\n",
        "# # pickle.dump(probCgivenY, open(file_name, 'wb'))\n",
        "# probCgivenX = pickle.load(open(file_name, 'rb'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UWu50k8pX0bb"
      },
      "source": [
        "multivariate_normal.pdf(C[0][0], GaussianMeans[0], GaussianCovMatrices[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uqki82tSBf0k"
      },
      "source": [
        "#IB ALgo\n",
        "N = num_of_clusters\n",
        "# print(\"Yaha\")\n",
        "while num_of_clusters>4:\n",
        "  # print(\"Here\")\n",
        "  i, j = np.argwhere(del_F == np.min(del_F)).ravel()\n",
        "  probCr = probC[i] + probC[j]\n",
        "  del_F[:,j] = np.inf\n",
        "  # probC.pop(j)\n",
        "  ClusterMapping[i] += ClusterMapping[j]\n",
        "  ClusterMapping[j] = []\n",
        "  probYgivenC[i] = (probYgivenC[i]*probC[i] + probYgivenC[j]*probC[j])/probCr\n",
        "  probC[i] = probCr\n",
        "  probCgivenX[i] = [0 for idx in probCgivenX[i]]\n",
        "  for idx in ClusterMapping[i]:\n",
        "    probCgivenX[i][idx] = 1\n",
        "  probXgivenC = ((np.array(probCgivenX)*np.array(probX)).T/probC).T\n",
        "  for idx in range(0, i):\n",
        "    temp1 = distance.jensenshannon(np.array(probYgivenC)[:,idx], np.array(probYgivenC)[:,i]) \n",
        "    temp2 = distance.jensenshannon(probXgivenC[idx], probXgivenC[i]) \n",
        "    dij = temp1 - (1/beta)*temp2\n",
        "    del_F[idx][i] = (probC[idx] + probC[i])*dij\n",
        "  for idx in range(i+1, N): \n",
        "    temp1 = distance.jensenshannon(np.array(probYgivenC)[:,i], np.array(probYgivenC)[:,idx]) \n",
        "    temp2 = distance.jensenshannon(probXgivenC[i], probXgivenC[idx]) \n",
        "    dij = temp1 - (1/beta)*temp2\n",
        "    del_F[i][idx] = (probC[i] + probC[idx])*dij\n",
        "  num_of_clusters = num_of_clusters-1\n",
        "  if num_of_clusters%100 == 0:\n",
        "    print(\"Clusters Rem: \", num_of_clusters)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YRS1Fh6o8w-l"
      },
      "source": [
        "# Start Prob [1,0,0,0] or [0.25]*4\n",
        "#transistion prob [0.25]\n",
        "clstrs = []\n",
        "for i in range(N):\n",
        "  if len(ClusterMapping[i]) !=0:\n",
        "    clstrs.append(ClusterMapping[i]);\n",
        "\n",
        "clstr_seq = np.ones((N,))*-1\n",
        "# --------------------------------------------------------------------------\n",
        "start_prob=np.ones((4,))/4.0\n",
        "# --------------------------------------------------------------------------\n",
        "id = 0;\n",
        "max_clstr = 0\n",
        "for clstr in clstrs:\n",
        "  id+=1\n",
        "  if len(clstr)>max:\n",
        "    max_clstr = len(clstr)\n",
        "hmm_wts = np.zeros((4,max_clstr)).astype('float')\n",
        "hmm_means = np.zeros((4,max_clstr,mfcc_feat.shape[-1]))\n",
        "hmm_covar = np.zeros((4,max_clstr,mfcc_feat.shape[-1],mfcc_feat.shape[-1]))\n",
        "\n",
        "id=-1\n",
        "for clstr in clstrs:\n",
        "  id+=1\n",
        "  clstr_wt = 1.0/len(clstr)\n",
        "  inclstr_id=0\n",
        "  for seg in clstr:\n",
        "    clstr_seq[inclstr_id]=id\n",
        "    hmm_wts[id][inclstr_id]=clstr_wt\n",
        "    hmm_means[id][inclstr_id]=GaussianMeans[seg]\n",
        "    hmm_covar[id][inclstr_id]=GaussianCovMatrices[seg]\n",
        "    inclstr_id+=1\n",
        "\n",
        "trans_prob = np.zeros((4,4))\n",
        "# --------------------------------------------------------------------------\n",
        "for i in range(1,N):\n",
        "  trans_prob[i-1][i]+=1\n",
        "trans_prob = np.divide(trans_prob.astype('float'),np.sum(trans_prob,axis=1))\n",
        "# --------------------------------------------------------------------------\n",
        "U_GMM_HMM =  hmmlearn.hmm.GMMHMM(n_components =4,\n",
        "                                 n_mix =N,\n",
        "                                 startprob_prior = start_prob,\n",
        "                                 transmat_prior  = trans_prob,\n",
        "                                 weights_prior  =hmm_wts ,\n",
        "                                 means_weight  = hmm_means,\n",
        "                                 covars_weight  = hmm_covar\n",
        "                                 )\n",
        "\n",
        "aligned_lbls = U_GMM_HMM.fit(mfcc_feat)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WDGYDOCXX1tQ"
      },
      "source": [
        "ClusterMapping"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aSR5s72TX2u0"
      },
      "source": [
        "p.pop(1)\n",
        "p.pop(3-1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ts618y0lX5yO"
      },
      "source": [
        "p"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i63Ltu_sYS-d"
      },
      "source": [
        "p.insert(1, 13)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dySuLF0rYj7z"
      },
      "source": [
        "d = dict(zip(range(10),[[i] for i in range(10)]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JQqH5QGnYkrf"
      },
      "source": [
        "d[0].append(2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IYqg3drNaCZA"
      },
      "source": [
        "d"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qoB9F6qOaM49"
      },
      "source": [
        "from scipy.stats import norm"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AfO6w38_ejRu",
        "outputId": "505d8f18-593d-4e87-abd7-da650ff56657",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 303
        }
      },
      "source": [
        "m,c = norm.fit(mfcc_feat[0:100],d=19)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-58-f88d49c2ed43>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnorm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmfcc_feat\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m19\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/scipy/stats/_continuous_distns.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, data, **kwds)\u001b[0m\n\u001b[1;32m    274\u001b[0m         \u001b[0mfscale\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'fscale'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    275\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 276\u001b[0;31m         \u001b[0m_remove_optimizer_parameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    277\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    278\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfloc\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfscale\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/scipy/stats/_continuous_distns.py\u001b[0m in \u001b[0;36m_remove_optimizer_parameters\u001b[0;34m(kwds)\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'optimizer'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Unknown arguments: %s.\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: Unknown arguments: {'d': 19}."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eWXWVGYMek4I"
      },
      "source": [
        "data = norm.rvs(loc=0,scale=2,size=10, )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q9U34Y1Oev_N",
        "outputId": "c5ad572d-c11d-4b53-b1c2-17f82d02473b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "c.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "()"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ifcW5chPexmQ",
        "outputId": "36329120-79db-44f0-ef54-725bc701cc39",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "mfcc_feat[0:100].shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(100, 19)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pfc3qtegfQOX"
      },
      "source": [
        "m = np.mean(mfcc_feat[0:100], axis = 0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mNC7qDvkfS4H"
      },
      "source": [
        "c = np.cov(mfcc_feat[0:100].T)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xvdwNlt7g8BZ",
        "outputId": "fe85bb38-0e12-4f39-c327-598da1ab484b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "m.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(19,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 107
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Mu4QPnphscO",
        "outputId": "7ecca6a5-aa41-4c64-9321-2c352032ed71",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "a = 1\n",
        "a +=2\n",
        "a"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BbPJg1nKAfW9"
      },
      "source": [
        "a = [[-10,-3,4], [4,-104,-500]]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QB7labgaKHKZ"
      },
      "source": [
        "i, j = np.argwhere(a == np.min(a)).ravel()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rIUkeqDCSAwZ"
      },
      "source": [
        "a = [1,2,3] + [3,4,5]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hEBNetzTZscl"
      },
      "source": [
        "a[0] = [9 for i in a[0]]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i4GEiihwadYA",
        "outputId": "07895ee0-102e-403b-89c2-093f60089957",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "a"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[9, 9, 9], [4, -104, -500]]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 188
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C5aXQx8OfGAI",
        "outputId": "f35e680e-2e97-4129-d8e2-aeaeb3a0cc9b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 316
        }
      },
      "source": [
        "import hmmlearn"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-036832e0c673>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mhmmlearn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'hmmlearn'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "deGGkkZOp7Wx"
      },
      "source": [
        "d"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eLmtU8On9EdS"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}