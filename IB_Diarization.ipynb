{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "IB_Diarization.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "17hU7udKV8_n35BJYo5ydfIPcbky2Mgz7",
      "authorship_tag": "ABX9TyNVhpsBKAtzxt8YB5cXqn1s",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cs16b108/IB_MDDP/blob/master/IB_Diarization.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "swlnTwsxvNy1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pip install webrtcvad"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dRgexiBuwreG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "from os.path import isfile, isdir, join\n",
        "from pathlib import Path\n",
        "import math\n",
        "import numpy as np\n",
        "# import numpy as np\n",
        "import random\n",
        "# import math\n",
        "from scipy.stats import multivariate_normal\n",
        "from matplotlib import pyplot as plt"
      ],
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5q7ATEL-rmQg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import collections\n",
        "import contextlib\n",
        "import sys\n",
        "import wave\n",
        "import webrtcvad\n",
        "\n",
        "\n",
        "def read_wave(path):\n",
        "    \"\"\"Reads a .wav file.\n",
        "    Takes the path, and returns (PCM audio data, sample rate).\n",
        "    \"\"\"\n",
        "    with contextlib.closing(wave.open(path, 'rb')) as wf:\n",
        "        num_channels = wf.getnchannels()\n",
        "        assert num_channels == 1\n",
        "        sample_width = wf.getsampwidth()\n",
        "        assert sample_width == 2\n",
        "        sample_rate = wf.getframerate()\n",
        "        assert sample_rate in (8000, 16000, 32000, 48000)\n",
        "        pcm_data = wf.readframes(wf.getnframes())\n",
        "        return pcm_data, sample_rate\n",
        "\n",
        "\n",
        "def write_wave(path, audio, sample_rate):\n",
        "    \"\"\"Writes a .wav file.\n",
        "    Takes path, PCM audio data, and sample rate.\n",
        "    \"\"\"\n",
        "    with contextlib.closing(wave.open(path, 'wb')) as wf:\n",
        "        wf.setnchannels(1)\n",
        "        wf.setsampwidth(2)\n",
        "        wf.setframerate(sample_rate)\n",
        "        wf.writeframes(audio)\n",
        "\n",
        "\n",
        "class Frame(object):\n",
        "    \"\"\"Represents a \"frame\" of audio data.\"\"\"\n",
        "    def __init__(self, bytes, timestamp, duration):\n",
        "        self.bytes = bytes\n",
        "        self.timestamp = timestamp\n",
        "        self.duration = duration\n",
        "\n",
        "\n",
        "def frame_generator(frame_duration_ms, audio, sample_rate):\n",
        "    \"\"\"Generates audio frames from PCM audio data.\n",
        "    Takes the desired frame duration in milliseconds, the PCM data, and\n",
        "    the sample rate.\n",
        "    Yields Frames of the requested duration.\n",
        "    \"\"\"\n",
        "    n = int(sample_rate * (frame_duration_ms / 1000.0) * 2)\n",
        "    offset = 0\n",
        "    timestamp = 0.0\n",
        "    duration = (float(n) / sample_rate) / 2.0\n",
        "    while offset + n < len(audio):\n",
        "        yield Frame(audio[offset:offset + n], timestamp, duration)\n",
        "        timestamp += duration\n",
        "        offset += n\n",
        "\n",
        "\n",
        "def vad_collector(sample_rate, frame_duration_ms,\n",
        "                  padding_duration_ms, vad, frames):\n",
        "    \"\"\"Filters out non-voiced audio frames.\n",
        "    Given a webrtcvad.Vad and a source of audio frames, yields only\n",
        "    the voiced audio.\n",
        "    Uses a padded, sliding window algorithm over the audio frames.\n",
        "    When more than 90% of the frames in the window are voiced (as\n",
        "    reported by the VAD), the collector triggers and begins yielding\n",
        "    audio frames. Then the collector waits until 90% of the frames in\n",
        "    the window are unvoiced to detrigger.\n",
        "    The window is padded at the front and back to provide a small\n",
        "    amount of silence or the beginnings/endings of speech around the\n",
        "    voiced frames.\n",
        "    Arguments:\n",
        "    sample_rate - The audio sample rate, in Hz.\n",
        "    frame_duration_ms - The frame duration in milliseconds.\n",
        "    padding_duration_ms - The amount to pad the window, in milliseconds.\n",
        "    vad - An instance of webrtcvad.Vad.\n",
        "    frames - a source of audio frames (sequence or generator).\n",
        "    Returns: A generator that yields PCM audio data.\n",
        "    \"\"\"\n",
        "    num_padding_frames = int(padding_duration_ms / frame_duration_ms)\n",
        "    # We use a deque for our sliding window/ring buffer.\n",
        "    ring_buffer = collections.deque(maxlen=num_padding_frames)\n",
        "    # We have two states: TRIGGERED and NOTTRIGGERED. We start in the\n",
        "    # NOTTRIGGERED state.\n",
        "    triggered = False\n",
        "\n",
        "    voiced_frames = []\n",
        "    for frame in frames:\n",
        "        is_speech = vad.is_speech(frame.bytes, sample_rate)\n",
        "\n",
        "        sys.stdout.write('1' if is_speech else '0')\n",
        "        if not triggered:\n",
        "            ring_buffer.append((frame, is_speech))\n",
        "            num_voiced = len([f for f, speech in ring_buffer if speech])\n",
        "            # If we're NOTTRIGGERED and more than 90% of the frames in\n",
        "            # the ring buffer are voiced frames, then enter the\n",
        "            # TRIGGERED state.\n",
        "            if num_voiced > 0.9 * ring_buffer.maxlen:\n",
        "                triggered = True\n",
        "                sys.stdout.write('+(%s)' % (ring_buffer[0][0].timestamp,))\n",
        "                # We want to yield all the audio we see from now until\n",
        "                # we are NOTTRIGGERED, but we have to start with the\n",
        "                # audio that's already in the ring buffer.\n",
        "                for f, s in ring_buffer:\n",
        "                    voiced_frames.append(f)\n",
        "                ring_buffer.clear()\n",
        "        else:\n",
        "            # We're in the TRIGGERED state, so collect the audio data\n",
        "            # and add it to the ring buffer.\n",
        "            voiced_frames.append(frame)\n",
        "            ring_buffer.append((frame, is_speech))\n",
        "            num_unvoiced = len([f for f, speech in ring_buffer if not speech])\n",
        "            # If more than 90% of the frames in the ring buffer are\n",
        "            # unvoiced, then enter NOTTRIGGERED and yield whatever\n",
        "            # audio we've collected.\n",
        "            if num_unvoiced > 0.9 * ring_buffer.maxlen:\n",
        "                sys.stdout.write('-(%s)' % (frame.timestamp + frame.duration))\n",
        "                triggered = False\n",
        "                yield b''.join([f.bytes for f in voiced_frames])\n",
        "                ring_buffer.clear()\n",
        "                voiced_frames = []\n",
        "    if triggered:\n",
        "        sys.stdout.write('-(%s)' % (frame.timestamp + frame.duration))\n",
        "    sys.stdout.write('\\n')\n",
        "    # If we have any leftover voiced audio when we run out of input,\n",
        "    # yield it.\n",
        "    if voiced_frames:\n",
        "        yield b''.join([f.bytes for f in voiced_frames])\n"
      ],
      "execution_count": 116,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i-3pVfLcvLEK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def main():\n",
        "    # if len(args) != 2:\n",
        "    #     sys.stderr.write(\n",
        "    #         'Usage: silenceremove.py <aggressiveness> <path to wav file>\\n')\n",
        "    #     sys.exit(1)\n",
        "    path = '/content/amicorpus/'\n",
        "    dir_list = sorted(os.listdir(path))\n",
        "    cnt = 0\n",
        "    for d in dir_list:\n",
        "      dir_name = join(path,d)\n",
        "      if isdir(dir_name):\n",
        "        filePath = join(path, d, 'audio', d+'.Mix-Headset.wav')\n",
        "        try:\n",
        "          audio, sample_rate = read_wave(filePath)\n",
        "          vad = webrtcvad.Vad(int(1))\n",
        "          frames = frame_generator(30, audio, sample_rate)\n",
        "          frames = list(frames)\n",
        "          segments = vad_collector(sample_rate, 30, 300, vad, frames)\n",
        "\n",
        "          # Segmenting the Voice audio and save it in list as bytes\n",
        "          concataudio = [segment for segment in segments]\n",
        "\n",
        "          joinedaudio = b\"\".join(concataudio)\n",
        "          writePath = join('/content/drive/My Drive/amicorpus_non_silence', d, 'audio')\n",
        "          Path(writePath).mkdir(parents=True, exist_ok=True)\n",
        "          write_wave(join(writePath, d+'.Mix-Headset.wav'), joinedaudio, sample_rate)\n",
        "          cnt += 1\n",
        "          # if(cnt == 2):\n",
        "          #   break\n",
        "        except:\n",
        "          print(\"Skipping: \", filePath)\n",
        "    print(\"Converted: \",cnt)\n",
        "if __name__ == '__main__':\n",
        "    main()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5sfjFF84ytNa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "rm -rf amicorpus_non_silence/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "htSasjGCqVdP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!chmod 755 amiBuild-13720-Mon-Aug-31-2020.wget.sh"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EDg3Y5_c6MWU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "547eb543-aba1-4024-8fe2-c84681f95570"
      },
      "source": [
        "!ls -l '/content/drive/My Drive/amicorpus_non_silence' | wc -l"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "98\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Et65yFWuq9HQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!./amiBuild-13720-Mon-Aug-31-2020.wget.sh"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WrmErGIIq-h2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!tar -czvf filename.tar.gz amicorpus"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nLvymyBTrWm_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!cp filename.tar.gz /content/drive/My\\ Drive/amicorpus.tar.gz"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i-kBMPPxxC5R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!tar -xzvf /content/drive/My\\ Drive/amicorpus.tar.gz"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dXtBCtSyswsR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "fb8ac7cc-ba63-46a7-f06e-c398da711785"
      },
      "source": [
        "join('abc', 'def', 'ncl')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'abc/def/ncl'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5e61p-wJwjuT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "da1e7596-f42d-4d06-8a34-7590e8fddce3"
      },
      "source": [
        "d = 'audio'\n",
        "d + '.Mix-Headset.wav'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'audio.Mix-Headset.wav'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_kHyv_MaxOhS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!./ComputeFeatures mfcc.config /content/drive/My\\ Drive/amicorpus_non_silence/ES2002b/audio/ES2002b.Mix-Headset.wav frameCepstrum+frameDeltaCepstrum sa1.mfcc 0.06 A"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ErlKnfIxkAIb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!chmod 755 ComputeFeatures"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gpFWEhYVkMV7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!chmod 755 mfcc.config"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hwwxwj47kPcg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pip install python_speech_features\n",
        "from python_speech_features import mfcc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZhXViBF7f3BM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import scipy.io.wavfile as wav"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "klZIk74SsRbr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "overlap = 0.02 #10 ms window shift\n",
        "fullPath = '/content/drive/My Drive/amicorpus_non_silence/ES2002b/audio/ES2002b.Mix-Headset.wav'\n",
        "(rate,sig) = wav.read(fullPath)\n",
        "mfcc_feat = mfcc(sig, rate, numcep = 19, nfilt = 40, winlen=0.03, winstep=overlap)"
      ],
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tA4XNF2XxeAx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "n, d = mfcc_feat.shape"
      ],
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NYpv2WHys4m6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# overlap = 0.01 #10 ms window shift\n",
        "init_cluster_time = 2500 #2.5sec\n",
        "init_cluster_len = math.ceil(init_cluster_time/(overlap*1000))"
      ],
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fttKNb7UtQ7z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "num_of_clusters = math.ceil(n/init_cluster_len)"
      ],
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t_AYZWAdxN_U",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "67996d84-fa42-4a88-a526-2d0e567c9926"
      },
      "source": [
        "num_of_clusters"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "812"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wlH4hUMdxnkA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "t = np.array_split(mfcc_feat, 3)"
      ],
      "execution_count": 108,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B2qzsMekx04_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class GMM:\n",
        "    def __init__(self, num_of_clusters):\n",
        "        self.num_of_clusters = num_of_clusters\n",
        "        self.log_likelihood =[]\n",
        "        self.LL_diff = []\n",
        "        # self.num_of_speakers = num_of_speakers\n",
        "\n",
        "    def gaussian_prob(self, x, mean, sigma):\n",
        "        d = x.shape[0]\n",
        "        p = ((2*math.pi)**(-d/2))*(np.linalg.det(sigma)**(-0.5))*np.exp(-0.5*(x-mean).reshape(d,1).T.dot(np.linalg.inv(sigma)).dot((x-mean).reshape(d,1)))\n",
        "        return p\n",
        "\n",
        "    def k_means(self, X):\n",
        "        n = X.shape[0]\n",
        "        d = X.shape[1]\n",
        "        itr = 0\n",
        "        #self.centroid = np.zeros((self.num_of_clusters, d), dtype = 'float64')\n",
        "        self.centroids = X[random.sample(range(n), self.num_of_clusters)]\n",
        "        self.cluster_assigned = np.zeros(n, dtype = int)\n",
        "        error = 0.0\n",
        "        while True:\n",
        "            print(\"Now at itr - \", itr)\n",
        "            # print(\"Centroids - \", self.centroids)\n",
        "            for i in range(n):\n",
        "                f_vec = X[i]\n",
        "                dist = np.sqrt(np.sum((f_vec-self.centroids)**2, 1))\n",
        "                # print(\"Dist Shape is - \", dist.shape)\n",
        "                self.cluster_assigned[i] = np.argmin(dist)\n",
        "            new_error = np.sum(np.sqrt(np.sum((X - self.centroids[self.cluster_assigned])**2, 1)))\n",
        "            if(itr>0):\n",
        "                print(\"Error Difference is - \", np.abs(error-new_error))\n",
        "            new_centroids = np.zeros((self.num_of_clusters, d), dtype = 'float64')\n",
        "            count_of_elements = np.zeros(self.num_of_clusters, dtype = int)\n",
        "            for i in range(n):\n",
        "                c_ind = self.cluster_assigned[i]\n",
        "                new_centroids[c_ind] += X[i]\n",
        "                count_of_elements[c_ind] += 1\n",
        "            new_centroids = new_centroids/count_of_elements[:,None]\n",
        "            if np.abs(new_error-error)<10 or np.array_equal(self.centroids, new_centroids) or itr>=5:\n",
        "                print(\"Breaking at itr - \", itr)\n",
        "                break\n",
        "            else:\n",
        "                self.centroids = np.copy(new_centroids)\n",
        "            itr += 1\n",
        "            error = new_error\n",
        "\n",
        "    def EM_GMM_INBUILT(self, X):\n",
        "        N = X.shape[0]\n",
        "        d = X.shape[1]\n",
        "        from sklearn.mixture import GaussianMixture as GMM\n",
        "        g = GMM(n_components=64, covariance_type = 'full', max_iter = 1)\n",
        "        g.fit(X)\n",
        "        print(\"Created\")\n",
        "\n",
        "    def EM_GMM(self, X):\n",
        "        N = X.shape[0]\n",
        "        d = X.shape[1]\n",
        "        self.cov_mat = np.zeros((self.num_of_clusters, d, d), dtype = 'float64')\n",
        "        self.gamma = np.zeros((N,self.num_of_clusters), dtype = 'float64')\n",
        "        likelihood = np.zeros((N,self.num_of_clusters), dtype = 'float64')\n",
        "        self.pi_prob = np.zeros(self.num_of_clusters, dtype = 'float64')\n",
        "        self.Nk = np.zeros(self.num_of_clusters, dtype = 'float64')\n",
        "        for k in range(self.num_of_clusters):\n",
        "            indices = (np.argwhere(self.cluster_assigned==k)).ravel()\n",
        "            X_k = X[indices]\n",
        "            X_k_centered = X_k - self.centroids[k]\n",
        "            self.Nk[k] = X_k.shape[0]\n",
        "            # print(\"Xk \",X_k.shape)\n",
        "            # print(\"Xkc \",X_k_centered.shape)\n",
        "            # print(\"cov mat \",self.cov_mat[k])\n",
        "            self.cov_mat[k] = (1/self.Nk[k])*(X_k_centered.T.dot(X_k_centered))\n",
        "        # print(self.Nk)\n",
        "        self.pi_prob = self.Nk/N\n",
        "        print(\"EM Begins\")\n",
        "        itr = 1\n",
        "        prev_log_likelihood = 0.0\n",
        "        \n",
        "        while True:\n",
        "            #####################################\n",
        "            ############   E Step   #############\n",
        "            #####################################\n",
        "            for k in range(self.num_of_clusters):\n",
        "                #self.gamma[i,k] = self.gaussian_prob(X[i], self.centroids[k], self.cov_mat[k])\n",
        "                self.cov_mat[k] += 1e-6*np.identity(d)\n",
        "                likelihood[:,k] =  multivariate_normal.pdf(X, self.centroids[k], self.cov_mat[k]).ravel()\n",
        "                # print(\"Done \", k)\n",
        "            # log_likelihood = np.sum(np.sum((likelihood*self.pi_prob), axis = 1))\n",
        "\n",
        "            # for i in range(N):\n",
        "            #     print(\"Done \",i)\n",
        "             \n",
        "            self.gamma = likelihood*self.pi_prob\n",
        "            self.gamma = self.gamma/(np.sum(self.gamma, axis = 1)[:,None])\n",
        "            # print(\"E done\")\n",
        "\n",
        "            #####################################\n",
        "            ############   M Step   #############\n",
        "            #####################################\n",
        "            self.Nk = np.sum(self.gamma, axis = 0)\n",
        "            self.pi_prob = self.Nk/N\n",
        "            for k in range(self.num_of_clusters):\n",
        "                self.centroids[k] = (1/self.Nk[k])*np.sum((X*self.gamma[:,k][:,np.newaxis]), axis = 0)\n",
        "                X_centered = X - self.centroids[k]\n",
        "                self.cov_mat[k] = (1/self.Nk[k])*((X_centered*self.gamma[:,k][:,np.newaxis]).T.dot(X_centered))\n",
        "            # print(\"M done\")\n",
        "\n",
        "            #####################################\n",
        "            ########   Log Likelihood   #########\n",
        "            #####################################\n",
        "            new_log_likelihood = np.sum(np.log(np.sum((likelihood*self.pi_prob), axis = 1)))\n",
        "            self.log_likelihood.append(new_log_likelihood)\n",
        "            diff_LL = np.abs(new_log_likelihood-prev_log_likelihood)\n",
        "            self.LL_diff.append(diff_LL)\n",
        "            print(\"Itr = \", itr, \" Current LL is - \",new_log_likelihood)\n",
        "            print(\"Change In LL is - \",diff_LL)\n",
        "            if(diff_LL<100 or itr>=10):\n",
        "                print(\"EM Finished at iteration - \", itr)\n",
        "                break\n",
        "            itr += 1\n",
        "            prev_log_likelihood = new_log_likelihood"
      ],
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T0j7BniJyGT-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 588
        },
        "outputId": "d0da6033-6fe3-4b61-9988-34722136fde9"
      },
      "source": [
        "ug = GMM(num_of_clusters)\n",
        "ug.k_means(mfcc_feat)\n",
        "ug.EM_GMM(mfcc_feat)"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Now at itr -  0\n",
            "Now at itr -  1\n",
            "Error Difference is -  376247.70135345636\n",
            "Now at itr -  2\n",
            "Error Difference is -  67175.10419689165\n",
            "Now at itr -  3\n",
            "Error Difference is -  28711.851844280027\n",
            "Now at itr -  4\n",
            "Error Difference is -  15926.86318728514\n",
            "Now at itr -  5\n",
            "Error Difference is -  10563.804716072511\n",
            "Breaking at itr -  5\n",
            "EM Begins\n",
            "Itr =  1  Current LL is -  -6763974.208030206\n",
            "Change In LL is -  6763974.208030206\n",
            "Itr =  2  Current LL is -  -6719287.087322179\n",
            "Change In LL is -  44687.12070802692\n",
            "Itr =  3  Current LL is -  -6695338.646181228\n",
            "Change In LL is -  23948.44114095159\n",
            "Itr =  4  Current LL is -  -6679947.446385758\n",
            "Change In LL is -  15391.199795469642\n",
            "Itr =  5  Current LL is -  -6668993.752974289\n",
            "Change In LL is -  10953.69341146946\n",
            "Itr =  6  Current LL is -  -6661653.686079189\n",
            "Change In LL is -  7340.066895099357\n",
            "Itr =  7  Current LL is -  -6656149.916194153\n",
            "Change In LL is -  5503.769885036163\n",
            "Itr =  8  Current LL is -  -6651833.96698823\n",
            "Change In LL is -  4315.949205922894\n",
            "Itr =  9  Current LL is -  -6648406.74464\n",
            "Change In LL is -  3427.2223482299596\n",
            "Itr =  10  Current LL is -  -6645568.702460884\n",
            "Change In LL is -  2838.042179116048\n",
            "EM Finished at iteration -  10\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O54Lqzff0zce",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def calc_prob(x, ug):\n",
        "  p = 0.0\n",
        "  D = x.shape[0]\n",
        "  for i in range(D):\n",
        "    s = x[i]\n",
        "    for k in range(ug.num_of_clusters):\n",
        "    #self.gamma[i,k] = self.gaussian_prob(X[i], self.centroids[k], self.cov_mat[k])\n",
        "      cov_matrix = 1e-6*np.identity(d) + ug.cov_mat[k]\n",
        "      # cov_matrix = \n",
        "      p =  p + ug.pi_prob[k]*multivariate_normal.pdf(s, ug.centroids[k], cov_matrix)\n",
        "  p = p/D\n",
        "  return p"
      ],
      "execution_count": 111,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wUZLV2W5RKZo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "########################\n",
        "##### IB Algorithm #####\n",
        "########################\n",
        "\n",
        "#Init Variables\n",
        "N = num_of_clusters\n",
        "C = np.array_split(mfcc_feat, num_of_clusters)\n",
        "prob_c = np.zeros(N, dtype = float)\n",
        "prob_cond_y_c = np.zeros((N, N), dtype = float)\n",
        "prob_cond_c_x = np.zeros((N, N), dtype = float)\n",
        "del_F = np.zeros((N, N), dtype = float)\n",
        "for i in range(N):\n",
        "  prob_c(i) = calc_prob(C[i], ug)\n",
        "  for j in range(N):\n",
        "    prob_cond_y_c[j][i] = calc_cond_prob(j, C[i], ug)\n",
        "    if(j == i):\n",
        "      prob_cond_c_x[j][i] = 1\n",
        "\n",
        "for i in range(N):\n",
        "  for j in range(i+1, N): \n",
        "    del_F[i][j] = cal_objective_diff(C[i], C[j])\n",
        "\n",
        "#Main Algo\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 114,
      "outputs": []
    }
  ]
}