{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "IB_Diarization_New.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cs16b108/IB_MDDP/blob/master/IB_Diarization_Latest.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D5jANRDmEMlV",
        "outputId": "c878806c-4192-472f-d933-032d73f99810",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A2xzt9uJrsZF",
        "outputId": "a898fe89-83e3-4d36-a3df-82292ad811bf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 598
        }
      },
      "source": [
        "!pip install webrtcvad\n",
        "!pip install hmmlearn==0.2.3\n",
        "!pip install python_speech_features\n",
        "!pip install xml"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting webrtcvad\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/89/34/e2de2d97f3288512b9ea56f92e7452f8207eb5a0096500badf9dfd48f5e6/webrtcvad-2.0.10.tar.gz (66kB)\n",
            "\r\u001b[K     |█████                           | 10kB 18.0MB/s eta 0:00:01\r\u001b[K     |██████████                      | 20kB 1.7MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 30kB 2.5MB/s eta 0:00:01\r\u001b[K     |███████████████████▉            | 40kB 3.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 51kB 2.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 61kB 2.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 71kB 2.2MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: webrtcvad\n",
            "  Building wheel for webrtcvad (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for webrtcvad: filename=webrtcvad-2.0.10-cp36-cp36m-linux_x86_64.whl size=71387 sha256=478d7ae01fb151388d7fd92075d3d893b7e71394681481eb63cefe55d247d118\n",
            "  Stored in directory: /root/.cache/pip/wheels/44/2a/18/bd1aec41cac7c3051fe95d92a6ed446122ea31dc713c432fa1\n",
            "Successfully built webrtcvad\n",
            "Installing collected packages: webrtcvad\n",
            "Successfully installed webrtcvad-2.0.10\n",
            "Collecting hmmlearn==0.2.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ff/7b/33f629a443a0671161c019e55c3f1b511c7e9fdce5ab8c8c3c33470eb939/hmmlearn-0.2.3-cp36-cp36m-manylinux1_x86_64.whl (363kB)\n",
            "\u001b[K     |████████████████████████████████| 368kB 2.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy>=0.15 in /usr/local/lib/python3.6/dist-packages (from hmmlearn==0.2.3) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.10 in /usr/local/lib/python3.6/dist-packages (from hmmlearn==0.2.3) (1.18.5)\n",
            "Requirement already satisfied: scikit-learn>=0.16 in /usr/local/lib/python3.6/dist-packages (from hmmlearn==0.2.3) (0.22.2.post1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.16->hmmlearn==0.2.3) (0.16.0)\n",
            "Installing collected packages: hmmlearn\n",
            "Successfully installed hmmlearn-0.2.3\n",
            "Collecting python_speech_features\n",
            "  Downloading https://files.pythonhosted.org/packages/ff/d1/94c59e20a2631985fbd2124c45177abaa9e0a4eee8ba8a305aa26fc02a8e/python_speech_features-0.6.tar.gz\n",
            "Building wheels for collected packages: python-speech-features\n",
            "  Building wheel for python-speech-features (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for python-speech-features: filename=python_speech_features-0.6-cp36-none-any.whl size=5887 sha256=b828513fbc114cf945928cb3653056a943abe78b2f2addc50fd15ebbc894333e\n",
            "  Stored in directory: /root/.cache/pip/wheels/3c/42/7c/f60e9d1b40015cd69b213ad90f7c18a9264cd745b9888134be\n",
            "Successfully built python-speech-features\n",
            "Installing collected packages: python-speech-features\n",
            "Successfully installed python-speech-features-0.6\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement xml (from versions: none)\u001b[0m\n",
            "\u001b[31mERROR: No matching distribution found for xml\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h4zv8xRTrsZU"
      },
      "source": [
        "import os\n",
        "from os.path import isfile, isdir, join\n",
        "from pathlib import Path\n",
        "import math\n",
        "import numpy as np\n",
        "# import numpy as np\n",
        "import random\n",
        "# import math\n",
        "from scipy.stats import multivariate_normal\n",
        "from matplotlib import pyplot as plt\n",
        "from scipy.spatial import distance\n",
        "import scipy.io.wavfile as wav\n",
        "from python_speech_features import mfcc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DHCZqd13rsZW"
      },
      "source": [
        "########################################################\n",
        "############## Read WAV and perform VAD ################\n",
        "## Already done once and files stored on google drive ##\n",
        "########################################################\n",
        "\n",
        "# import collections\n",
        "# import contextlib\n",
        "# import sys\n",
        "# import wave\n",
        "# import webrtcvad\n",
        "\n",
        "\n",
        "# def read_wave(path):\n",
        "#     \"\"\"Reads a .wav file.\n",
        "#     Takes the path, and returns (PCM audio data, sample rate).\n",
        "#     \"\"\"\n",
        "#     with contextlib.closing(wave.open(path, 'rb')) as wf:\n",
        "#         num_channels = wf.getnchannels()\n",
        "#         assert num_channels == 1\n",
        "#         sample_width = wf.getsampwidth()\n",
        "#         assert sample_width == 2\n",
        "#         sample_rate = wf.getframerate()\n",
        "#         assert sample_rate in (8000, 16000, 32000, 48000)\n",
        "#         pcm_data = wf.readframes(wf.getnframes())\n",
        "#         return pcm_data, sample_rate\n",
        "\n",
        "\n",
        "# def write_wave(path, audio, sample_rate):\n",
        "#     \"\"\"Writes a .wav file.\n",
        "#     Takes path, PCM audio data, and sample rate.\n",
        "#     \"\"\"\n",
        "#     with contextlib.closing(wave.open(path, 'wb')) as wf:\n",
        "#         wf.setnchannels(1)\n",
        "#         wf.setsampwidth(2)\n",
        "#         wf.setframerate(sample_rate)\n",
        "#         wf.writeframes(audio)\n",
        "\n",
        "\n",
        "# class Frame(object):\n",
        "#     \"\"\"Represents a \"frame\" of audio data.\"\"\"\n",
        "#     def __init__(self, bytes, timestamp, duration):\n",
        "#         self.bytes = bytes\n",
        "#         self.timestamp = timestamp\n",
        "#         self.duration = duration\n",
        "\n",
        "\n",
        "# def frame_generator(frame_duration_ms, audio, sample_rate):\n",
        "#     \"\"\"Generates audio frames from PCM audio data.\n",
        "#     Takes the desired frame duration in milliseconds, the PCM data, and\n",
        "#     the sample rate.\n",
        "#     Yields Frames of the requested duration.\n",
        "#     \"\"\"\n",
        "#     n = int(sample_rate * (frame_duration_ms / 1000.0) * 2)\n",
        "#     offset = 0\n",
        "#     timestamp = 0.0\n",
        "#     duration = (float(n) / sample_rate) / 2.0\n",
        "#     while offset + n < len(audio):\n",
        "#         yield Frame(audio[offset:offset + n], timestamp, duration)\n",
        "#         timestamp += duration\n",
        "#         offset += n\n",
        "\n",
        "\n",
        "# def vad_collector(sample_rate, frame_duration_ms,\n",
        "#                   padding_duration_ms, vad, frames,vuv_frames):\n",
        "#     \"\"\"Filters out non-voiced audio frames.\n",
        "#     Given a webrtcvad.Vad and a source of audio frames, yields only\n",
        "#     the voiced audio.\n",
        "#     Uses a padded, sliding window algorithm over the audio frames.\n",
        "#     When more than 90% of the frames in the window are voiced (as\n",
        "#     reported by the VAD), the collector triggers and begins yielding\n",
        "#     audio frames. Then the collector waits until 90% of the frames in\n",
        "#     the window are unvoiced to detrigger.\n",
        "#     The window is padded at the front and back to provide a small\n",
        "#     amount of silence or the beginnings/endings of speech around the\n",
        "#     voiced frames.\n",
        "#     Arguments:\n",
        "#     sample_rate - The audio sample rate, in Hz.\n",
        "#     frame_duration_ms - The frame duration in milliseconds.\n",
        "#     padding_duration_ms - The amount to pad the window, in milliseconds.\n",
        "#     vad - An instance of webrtcvad.Vad.\n",
        "#     frames - a source of audio frames (sequence or generator).\n",
        "#     Returns: A generator that yields PCM audio data.\n",
        "#     \"\"\"\n",
        "#     num_padding_frames = int(padding_duration_ms / frame_duration_ms)\n",
        "#     # We use a deque for our sliding window/ring buffer.\n",
        "#     ring_buffer = collections.deque(maxlen=num_padding_frames)\n",
        "#     # We have two states: TRIGGERED and NOTTRIGGERED. We start in the\n",
        "#     # NOTTRIGGERED state.\n",
        "#     triggered = False\n",
        "\n",
        "#     index=-1\n",
        "#     voiced_frames = []\n",
        "#     for frame in frames:\n",
        "\n",
        "#         index+=1\n",
        "#         is_speech = vad.is_speech(frame.bytes, sample_rate)\n",
        "\n",
        "#         sys.stdout.write('1' if is_speech else '0')\n",
        "#         if not triggered:\n",
        "#             ring_buffer.append((frame, is_speech))\n",
        "#             num_voiced = len([f for f, speech in ring_buffer if speech])\n",
        "#             # If we're NOTTRIGGERED and more than 90% of the frames in\n",
        "#             # the ring buffer are voiced frames, then enter the\n",
        "#             # TRIGGERED state.\n",
        "#             if num_voiced > 0.9 * ring_buffer.maxlen:\n",
        "#                 triggered = True\n",
        "#                 sys.stdout.write('+(%s)' % (ring_buffer[0][0].timestamp,))\n",
        "#                 # We want to yield all the audio we see from now until\n",
        "#                 # we are NOTTRIGGERED, but we have to start with the\n",
        "#                 # audio that's already in the ring buffer.\n",
        "\n",
        "#                 id = 0 #we must start actually with num_padding_frames-1 and do index-- \n",
        "#                 for f, s in ring_buffer:\n",
        "#                     voiced_frames.append(f)\n",
        "#                     vuv_frames[index-id]=1\n",
        "#                     id+=1\n",
        "\n",
        "#                 ring_buffer.clear()\n",
        "#         else:\n",
        "#             # We're in the TRIGGERED state, so collect the audio data\n",
        "#             # and add it to the ring buffer.\n",
        "#             voiced_frames.append(frame)\n",
        "#             vuv_frames[index] = 1\n",
        "#             ring_buffer.append((frame, is_speech))\n",
        "#             num_unvoiced = len([f for f, speech in ring_buffer if not speech])\n",
        "#             # If more than 90% of the frames in the ring buffer are\n",
        "#             # unvoiced, then enter NOTTRIGGERED and yield whatever\n",
        "#             # audio we've collected.\n",
        "#             if num_unvoiced > 0.9 * ring_buffer.maxlen:\n",
        "#                 sys.stdout.write('-(%s)' % (frame.timestamp + frame.duration))\n",
        "#                 triggered = False\n",
        "#                 yield b''.join([f.bytes for f in voiced_frames])\n",
        "#                 ring_buffer.clear()\n",
        "#                 voiced_frames = []\n",
        "#     if triggered:\n",
        "#         sys.stdout.write('-(%s)' % (frame.timestamp + frame.duration))\n",
        "#     sys.stdout.write('\\n')\n",
        "#     # If we have any leftover voiced audio when we run out of input,\n",
        "#     # yield it.\n",
        "#     if voiced_frames:\n",
        "#         yield b''.join([f.bytes for f in voiced_frames])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "na0eIG-qrsZY"
      },
      "source": [
        "# def main():\n",
        "#     # if len(args) != 2:\n",
        "#     #     sys.stderr.write(\n",
        "#     #         'Usage: silenceremove.py <aggressiveness> <path to wav file>\\n')\n",
        "#     #     sys.exit(1)\n",
        "#     path = '/content/amicorpus/'\n",
        "#     dir_list = sorted(os.listdir(path))\n",
        "#     cnt = 0\n",
        "#     for d in dir_list:\n",
        "#       dir_name = join(path,d)\n",
        "#       if isdir(dir_name):\n",
        "#         filePath = join(path, d, 'audio', d+'.Mix-Headset.wav')\n",
        "#         try:\n",
        "#           audio, sample_rate = read_wave(filePath)\n",
        "#           vad = webrtcvad.Vad(int(1))\n",
        "#           frames = frame_generator(30, audio, sample_rate)\n",
        "#           frames = list(frames)\n",
        "#           nof_frames = 1+(len(audio)-1)/int(sample_rate * (frame_duration_ms / 1000.0) * 2)\n",
        "#           vuv_frames = np.zeros((nof_frames],)) \n",
        "#           segments = vad_collector(sample_rate, 30, 300, vad, frames,vuv_frames)\n",
        "\n",
        "#           # Segmenting the Voice audio and save it in list as bytes\n",
        "#           concataudio = [segment for segment in segments]\n",
        "\n",
        "#           joinedaudio = b\"\".join(concataudio)\n",
        "#           writePath = join('/content/drive/My Drive/IB_Diarization/amicorpus_non_silence', d, 'audio')\n",
        "#           Path(writePath).mkdir(parents=True, exist_ok=True)\n",
        "#           write_wave(join(writePath, d+'.Mix-Headset.wav'), joinedaudio, sample_rate)\n",
        "#           cnt += 1\n",
        "#           # if(cnt == 2):\n",
        "#           #   break\n",
        "#         except:\n",
        "#           print(\"Skipping: \", filePath)\n",
        "#     print(\"Converted: \",cnt)\n",
        "# if __name__ == '__main__':\n",
        "#     main()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mR0Yhd0OrsZb"
      },
      "source": [
        "# rm -rf amicorpus_non_silence/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LqNiYH1QrsZd"
      },
      "source": [
        "# !chmod 755 amiBuild-13720-Mon-Aug-31-2020.wget.sh"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9euMwS6NrsZf"
      },
      "source": [
        "# !ls -l '/content/drive/My Drive/amicorpus_non_silence' | wc -l"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C8RJQMUbrsZh"
      },
      "source": [
        "# !./amiBuild-13720-Mon-Aug-31-2020.wget.sh"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n0k0Zr8IrsZj"
      },
      "source": [
        "# !tar -czvf filename.tar.gz amicorpus"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oR1tYAM5rsZl"
      },
      "source": [
        "# !cp filename.tar.gz /content/drive/My\\ Drive/amicorpus.tar.gz"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fZIAuddBrsZn"
      },
      "source": [
        "# !tar -xzvf /content/drive/My\\ Drive/amicorpus.tar.gz"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9SQrCOiIrsZp"
      },
      "source": [
        "# !./ComputeFeatures mfcc.config /content/drive/My\\ Drive/amicorpus_non_silence/ES2002b/audio/ES2002b.Mix-Headset.wav frameCepstrum+frameDeltaCepstrum sa1.mfcc 0.06 A"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FuIsCQE6rsZs"
      },
      "source": [
        "# !chmod 755 ComputeFeatures"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LHq9U1yQrsZv"
      },
      "source": [
        "# !chmod 755 mfcc.config"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZePchLWDrsZx"
      },
      "source": [
        "####################################\n",
        "### Actual Code Starts from Here ###\n",
        "####################################"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mMQYh3vgFXzO",
        "outputId": "6dc8ac9a-bebc-43ea-8c7a-ed921e9d481e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        }
      },
      "source": [
        "%cd '/content/drive/My Drive/IB_Diarization/amicorpus_non_silence/ES2002b/audio/'\n",
        "!ls\n",
        "%cd /content"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/IB_Diarization/amicorpus_non_silence/ES2002b/audio\n",
            "ES2002b.Mix-Headset.wav\n",
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ekr76KGrsZ0"
      },
      "source": [
        "#Define path to wav files created after VAD\n",
        "path = '/content/drive/My Drive/IB_Diarization/amicorpus_non_silence/'\n",
        "\n",
        "overlap = 0.01 #10 ms window shift\n",
        "fullPath = join(path,'ES2002b/audio/ES2002b.Mix-Headset.wav')\n",
        "(rate,sig) = wav.read(fullPath)\n",
        "mfcc_feat = mfcc(sig, rate, numcep = 19, nfilt = 26, winlen=0.03, winstep=overlap)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tA4XNF2XxeAx"
      },
      "source": [
        "n, d = mfcc_feat.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NYpv2WHys4m6"
      },
      "source": [
        "# overlap = 0.01 #10 ms window shift\n",
        "init_cluster_time = 2500 #2.5sec\n",
        "init_cluster_len = math.ceil(init_cluster_time/(overlap*1000))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fttKNb7UtQ7z"
      },
      "source": [
        "num_of_clusters = math.ceil(n/init_cluster_len)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t_AYZWAdxN_U",
        "outputId": "c2df5932-b114-42e3-ddc6-352354b30abc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "source": [
        "num_of_clusters"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "812"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wlH4hUMdxnkA"
      },
      "source": [
        "t = np.array_split(mfcc_feat, 3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B2qzsMekx04_"
      },
      "source": [
        "class GMM:\n",
        "    def __init__(self, num_of_clusters):\n",
        "        self.num_of_clusters = num_of_clusters\n",
        "        self.log_likelihood =[]\n",
        "        self.LL_diff = []\n",
        "        # self.num_of_speakers = num_of_speakers\n",
        "\n",
        "    def gaussian_prob(self, x, mean, sigma):\n",
        "        d = x.shape[0]\n",
        "        p = ((2*math.pi)**(-d/2))*(np.linalg.det(sigma)**(-0.5))*np.exp(-0.5*(x-mean).reshape(d,1).T.dot(np.linalg.inv(sigma)).dot((x-mean).reshape(d,1)))\n",
        "        return p\n",
        "\n",
        "    def k_means(self, X):\n",
        "        n = X.shape[0]\n",
        "        d = X.shape[1]\n",
        "        itr = 0\n",
        "        #self.centroid = np.zeros((self.num_of_clusters, d), dtype = 'float64')\n",
        "        self.centroids = X[random.sample(range(n), self.num_of_clusters)]\n",
        "        self.cluster_assigned = np.zeros(n, dtype = int)\n",
        "        error = 0.0\n",
        "        while True:\n",
        "            print(\"Now at itr - \", itr)\n",
        "            # print(\"Centroids - \", self.centroids)\n",
        "            for i in range(n):\n",
        "                f_vec = X[i]\n",
        "                dist = np.sqrt(np.sum((f_vec-self.centroids)**2, 1))\n",
        "                # print(\"Dist Shape is - \", dist.shape)\n",
        "                self.cluster_assigned[i] = np.argmin(dist)\n",
        "            new_error = np.sum(np.sqrt(np.sum((X - self.centroids[self.cluster_assigned])**2, 1)))\n",
        "            if(itr>0):\n",
        "                print(\"Error Difference is - \", np.abs(error-new_error))\n",
        "            new_centroids = np.zeros((self.num_of_clusters, d), dtype = 'float64')\n",
        "            count_of_elements = np.zeros(self.num_of_clusters, dtype = int)\n",
        "            for i in range(n):\n",
        "                c_ind = self.cluster_assigned[i]\n",
        "                new_centroids[c_ind] += X[i]\n",
        "                count_of_elements[c_ind] += 1\n",
        "            new_centroids = new_centroids/count_of_elements[:,None]\n",
        "            if np.abs(new_error-error)<10 or np.array_equal(self.centroids, new_centroids) or itr>=5:\n",
        "                print(\"Breaking at itr - \", itr)\n",
        "                break\n",
        "            else:\n",
        "                self.centroids = np.copy(new_centroids)\n",
        "            itr += 1\n",
        "            error = new_error\n",
        "\n",
        "    def EM_GMM_INBUILT(self, X):\n",
        "        N = X.shape[0]\n",
        "        d = X.shape[1]\n",
        "        from sklearn.mixture import GaussianMixture as GMM\n",
        "        g = GMM(n_components=64, covariance_type = 'full', max_iter = 1)\n",
        "        g.fit(X)\n",
        "        print(\"Created\")\n",
        "\n",
        "    def EM_GMM(self, X):\n",
        "        N = X.shape[0]\n",
        "        d = X.shape[1]\n",
        "        self.cov_mat = np.zeros((self.num_of_clusters, d, d), dtype = 'float64')\n",
        "        self.gamma = np.zeros((N,self.num_of_clusters), dtype = 'float64')\n",
        "        likelihood = np.zeros((N,self.num_of_clusters), dtype = 'float64')\n",
        "        self.pi_prob = np.zeros(self.num_of_clusters, dtype = 'float64')\n",
        "        self.Nk = np.zeros(self.num_of_clusters, dtype = 'float64')\n",
        "        for k in range(self.num_of_clusters):\n",
        "            indices = (np.argwhere(self.cluster_assigned==k)).ravel()\n",
        "            X_k = X[indices]\n",
        "            X_k_centered = X_k - self.centroids[k]\n",
        "            self.Nk[k] = X_k.shape[0]\n",
        "            # print(\"Xk \",X_k.shape)\n",
        "            # print(\"Xkc \",X_k_centered.shape)\n",
        "            # print(\"cov mat \",self.cov_mat[k])\n",
        "            self.cov_mat[k] = (1/self.Nk[k])*(X_k_centered.T.dot(X_k_centered))\n",
        "        # print(self.Nk)\n",
        "        self.pi_prob = self.Nk/N\n",
        "        print(\"EM Begins\")\n",
        "        itr = 1\n",
        "        prev_log_likelihood = 0.0\n",
        "        \n",
        "        while True:\n",
        "            #####################################\n",
        "            ############   E Step   #############\n",
        "            #####################################\n",
        "            for k in range(self.num_of_clusters):\n",
        "                #self.gamma[i,k] = self.gaussian_prob(X[i], self.centroids[k], self.cov_mat[k])\n",
        "                self.cov_mat[k] += 1e-6*np.identity(d)\n",
        "                likelihood[:,k] =  multivariate_normal.pdf(X, self.centroids[k], self.cov_mat[k]).ravel()\n",
        "                # print(\"Done \", k)\n",
        "            # log_likelihood = np.sum(np.sum((likelihood*self.pi_prob), axis = 1))\n",
        "\n",
        "            # for i in range(N):\n",
        "            #     print(\"Done \",i)\n",
        "             \n",
        "            self.gamma = likelihood*self.pi_prob\n",
        "            self.gamma = self.gamma/(np.sum(self.gamma, axis = 1)[:,None])\n",
        "            # print(\"E done\")\n",
        "\n",
        "            #####################################\n",
        "            ############   M Step   #############\n",
        "            #####################################\n",
        "            self.Nk = np.sum(self.gamma, axis = 0)\n",
        "            self.pi_prob = self.Nk/N\n",
        "            for k in range(self.num_of_clusters):\n",
        "                self.centroids[k] = (1/self.Nk[k])*np.sum((X*self.gamma[:,k][:,np.newaxis]), axis = 0)\n",
        "                X_centered = X - self.centroids[k]\n",
        "                self.cov_mat[k] = (1/self.Nk[k])*((X_centered*self.gamma[:,k][:,np.newaxis]).T.dot(X_centered))\n",
        "            # print(\"M done\")\n",
        "\n",
        "            #####################################\n",
        "            ########   Log Likelihood   #########\n",
        "            #####################################\n",
        "            new_log_likelihood = np.sum(np.log(np.sum((likelihood*self.pi_prob), axis = 1)))\n",
        "            self.log_likelihood.append(new_log_likelihood)\n",
        "            diff_LL = np.abs(new_log_likelihood-prev_log_likelihood)\n",
        "            self.LL_diff.append(diff_LL)\n",
        "            print(\"Itr = \", itr, \" Current LL is - \",new_log_likelihood)\n",
        "            print(\"Change In LL is - \",diff_LL)\n",
        "            if(diff_LL<100 or itr>=10):\n",
        "                print(\"EM Finished at iteration - \", itr)\n",
        "                break\n",
        "            itr += 1\n",
        "            prev_log_likelihood = new_log_likelihood"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T0j7BniJyGT-"
      },
      "source": [
        "# ug = GMM(num_of_clusters)\n",
        "# ug.k_means(mfcc_feat)\n",
        "# ug.EM_GMM(mfcc_feat)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ihYpZGpIY5WX"
      },
      "source": [
        "def fitUnimodal(C):\n",
        "  means = []\n",
        "  covMatrices = []\n",
        "  for c in C:\n",
        "    means.append(np.mean(c, axis = 0))\n",
        "    covMatrices.append(np.cov(c.T))\n",
        "  return means, covMatrices"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O54Lqzff0zce"
      },
      "source": [
        "def calc_prob(x, GaussianMeans, GaussianCovMatrices):\n",
        "  p = 0.0\n",
        "  D = x.shape[0]\n",
        "  numOfClusters = len(GaussianMeans)\n",
        "  for i in range(D):\n",
        "    s = x[i]\n",
        "    for k in range(numOfClusters):\n",
        "    #self.gamma[i,k] = self.gaussian_prob(X[i], self.centroids[k], self.cov_mat[k])\n",
        "      cov_matrix = 1e-6*np.identity(d) + GaussianCovMatrices[k]\n",
        "      # cov_matrix = \n",
        "      p =  p + ug.pi_prob[k]*multivariate_normal.pdf(s, ug.centroids[k], cov_matrix)\n",
        "  p = p/D\n",
        "  return p"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Y7msXyWJkMH"
      },
      "source": [
        "def calcYgivenX(x, GaussianMeans, GaussianCovMatrices, i):\n",
        "  p = 0.0\n",
        "  numOfClusters = len(GaussianMeans)\n",
        "  w = 1.0/numOfClusters\n",
        "  D = x.shape[0]\n",
        "  probMat = np.zeros((D, num_of_clusters), dtype = float)\n",
        "  for i in range(num_of_clusters):\n",
        "    probMat[:,i] = multivariate_normal(x, GaussianMeans[i], GaussianCovMatrices[i])\n",
        "  p = 0.0\n",
        "  self.gamma = self.gamma/(np.sum(self.gamma, axis = 1)[:,None]) \n",
        "  return p"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wUZLV2W5RKZo"
      },
      "source": [
        "########################\n",
        "##### IB Algorithm #####\n",
        "########################\n",
        "\n",
        "#Init Variables\n",
        "N = num_of_clusters\n",
        "C = np.array_split(mfcc_feat, num_of_clusters)\n",
        "GaussianMeans, GaussianCovMatrices = fitUnimodal(C)\n",
        "ClusterMapping = dict(zip(range(num_of_clusters), [[i] for i in range(num_of_clusters)]))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0zDI3qIlQHei"
      },
      "source": [
        "probC = []\n",
        "for i in range(N):\n",
        "  p = 0.0\n",
        "  D = C[i].shape[0]\n",
        "  for j in range(D):\n",
        "    s = C[i][j]\n",
        "    p += multivariate_normal.pdf(s, GaussianMeans[i], GaussianCovMatrices[i])\n",
        "  p = p/D \n",
        "  probC.append(p)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FQejbER_OfF9"
      },
      "source": [
        "probC = (1.0/N)*np.ones(N)\n",
        "probX = probC.copy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tfyeSjbwyHgY",
        "outputId": "c8df805e-d7d3-4cbf-eb14-ee247670e7ac",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        }
      },
      "source": [
        "probYgivenC = []\n",
        "probCgivenX = []\n",
        "for i in range(N):\n",
        "  temp1 = []\n",
        "  temp2 = []\n",
        "  x = C[i]\n",
        "  w = 1.0/num_of_clusters\n",
        "  D = x.shape[0]\n",
        "  probMat = np.zeros((D, num_of_clusters), dtype = float)\n",
        "  for j in range(num_of_clusters):\n",
        "    probMat[:,j] = multivariate_normal.pdf(x, GaussianMeans[j], GaussianCovMatrices[j]).ravel()\n",
        "  probMat = probMat/(np.sum(probMat, axis = 1)[:,None])\n",
        "  temp1 = np.mean(probMat, axis = 0)\n",
        "  for j in range(N):\n",
        "    # p = probMat[i,j]/(np.sum(probMat[i,j], axis = 1)[:,None])\n",
        "    # p = calcYgivenX(x, GaussianMeans, GaussianCovMatrices, i)\n",
        "    # temp1.append(p)\n",
        "    if j == i:\n",
        "      temp2.append(1.0)\n",
        "    else:\n",
        "      temp2.append(0.0)\n",
        "    # print(\"Done2 \",j)\n",
        "  probYgivenC.append(temp1)\n",
        "  probCgivenX.append(temp2)\n",
        "  if i%100 == 0:\n",
        "    print(\"Done \",i)\n",
        "\n",
        "# # prob_cond_y_c = np.zeros((N, N), dtype = float)\n",
        "# # prob_cond_c_x = np.zeros((N, N), dtype = float)\n",
        "# del_F = np.zeros((N, N), dtype = float)\n",
        "# for i in range(N):\n",
        "#   prob_c(i) = calc_prob(C[i], ug)\n",
        "#   for j in range(N):\n",
        "#     prob_cond_y_c[j][i] = calc_cond_prob(j, C[i], ug)\n",
        "#     if(j == i):\n",
        "#       prob_cond_c_x[j][i] = 1\n",
        "\n",
        "\n",
        "\n",
        "#Main Algo\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Done  0\n",
            "Done  100\n",
            "Done  200\n",
            "Done  300\n",
            "Done  400\n",
            "Done  500\n",
            "Done  600\n",
            "Done  700\n",
            "Done  800\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fy1GaieALLwB",
        "outputId": "2d66143d-1d8e-4ac5-8811-9d775b61e8a0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        }
      },
      "source": [
        "beta = 10.0\n",
        "del_F = np.zeros((N, N), dtype = float)\n",
        "del_F[:,:] = np.inf\n",
        "probXgivenC = ((np.array(probCgivenX)*np.array(probX)).T/probC).T\n",
        "for i in range(N):\n",
        "  for j in range(i+1, N): \n",
        "    temp1 = distance.jensenshannon(np.array(probYgivenC)[:,i], np.array(probYgivenC)[:,j]) \n",
        "    temp2 = distance.jensenshannon(probXgivenC[i], probXgivenC[j]) \n",
        "    dij = temp1 - (1/beta)*temp2\n",
        "    del_F[i][j] = (probC[i] + probC[j])*dij\n",
        "    # del_F[i][j] = cal_objective_diff(C[i], C[j])\n",
        "  if i%100 == 0:\n",
        "    print(\"Done \",i)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Done  0\n",
            "Done  100\n",
            "Done  200\n",
            "Done  300\n",
            "Done  400\n",
            "Done  500\n",
            "Done  600\n",
            "Done  700\n",
            "Done  800\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yDS5A-pRVE_L"
      },
      "source": [
        "# !cp  /content/drive/My\\ Drive/IB_Diarization/*.sav /content/\n",
        "!cp /content/*.sav  /content/drive/My\\ Drive/IB_Diarization/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3UBnkJ0-Bgl5"
      },
      "source": [
        "import pickle\n",
        "file_name = \"probYgivenC.sav\"\n",
        "pickle.dump(probYgivenC, open(file_name, 'wb'))\n",
        "file_name = \"probCgivenX.sav\"\n",
        "pickle.dump(probCgivenX, open(file_name, 'wb'))\n",
        "file_name = \"del_F.sav\"\n",
        "pickle.dump(del_F, open(file_name, 'wb'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lAcZYLCvL-By"
      },
      "source": [
        "# file_name = \"probYgivenC.sav\"\n",
        "# probYgivenC = pickle.load(open(file_name, 'rb'))\n",
        "# file_name = \"probCgivenX.sav\"\n",
        "# # pickle.dump(probCgivenY, open(file_name, 'wb'))\n",
        "# probCgivenX = pickle.load(open(file_name, 'rb'))\n",
        "# file_name = \"del_F.sav\"\n",
        "# del_F = pickle.load(open(file_name, 'rb'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UWu50k8pX0bb"
      },
      "source": [
        "multivariate_normal.pdf(C[0][0], GaussianMeans[0], GaussianCovMatrices[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uqki82tSBf0k",
        "outputId": "40f39740-f9f5-49f1-9bc7-095d9e129654",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 166
        }
      },
      "source": [
        "#IB ALgo\n",
        "N = num_of_clusters\n",
        "# print(\"Yaha\")\n",
        "while num_of_clusters>4:\n",
        "  # print(\"Here\")\n",
        "  # i, j = np.argwhere(del_F == np.min(del_F)).ravel()\n",
        "  mIdx = np.argmin(del_F)\n",
        "  i = mIdx//N\n",
        "  j = mIdx%N\n",
        "  probCr = probC[i] + probC[j]\n",
        "  del_F[:,j] = np.inf\n",
        "  del_F[j,:] = np.inf\n",
        "  # probC.pop(j)\n",
        "  ClusterMapping[i] += ClusterMapping[j]\n",
        "  ClusterMapping[j] = []\n",
        "  probYgivenC[i] = (probYgivenC[i]*probC[i] + probYgivenC[j]*probC[j])/probCr\n",
        "  probC[i] = probCr\n",
        "  probCgivenX[i] = [0 for idx in probCgivenX[i]]\n",
        "  for idx in ClusterMapping[i]:\n",
        "    probCgivenX[i][idx] = 1\n",
        "  probXgivenC = ((np.array(probCgivenX)*np.array(probX)).T/probC).T\n",
        "  for idx in range(0, i):\n",
        "    if del_F[idx,i] == np.inf:\n",
        "      continue\n",
        "    temp1 = distance.jensenshannon(np.array(probYgivenC)[:,idx], np.array(probYgivenC)[:,i]) \n",
        "    temp2 = distance.jensenshannon(probXgivenC[idx], probXgivenC[i]) \n",
        "    dij = temp1 - (1/beta)*temp2\n",
        "    del_F[idx][i] = (probC[idx] + probC[i])*dij\n",
        "  for idx in range(i+1, N):\n",
        "    if del_F[i, idx] == np.inf:\n",
        "      continue \n",
        "    temp1 = distance.jensenshannon(np.array(probYgivenC)[:,i], np.array(probYgivenC)[:,idx]) \n",
        "    temp2 = distance.jensenshannon(probXgivenC[i], probXgivenC[idx]) \n",
        "    dij = temp1 - (1/beta)*temp2\n",
        "    del_F[i][idx] = (probC[i] + probC[idx])*dij\n",
        "  num_of_clusters = num_of_clusters-1\n",
        "  if num_of_clusters%100 == 0:\n",
        "    print(\"Clusters Rem: \", num_of_clusters)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Clusters Rem:  800\n",
            "Clusters Rem:  700\n",
            "Clusters Rem:  600\n",
            "Clusters Rem:  500\n",
            "Clusters Rem:  400\n",
            "Clusters Rem:  300\n",
            "Clusters Rem:  200\n",
            "Clusters Rem:  100\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WDGYDOCXX1tQ",
        "outputId": "7f86e765-149e-4094-f7db-974c553a053c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "file_name = \"ClusterMapping.sav\"\n",
        "pickle.dump(ClusterMapping, open(file_name, 'wb'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: [0,\n",
              "  810,\n",
              "  2,\n",
              "  3,\n",
              "  240,\n",
              "  811,\n",
              "  260,\n",
              "  389,\n",
              "  82,\n",
              "  90,\n",
              "  253,\n",
              "  699,\n",
              "  189,\n",
              "  204,\n",
              "  433,\n",
              "  235,\n",
              "  341,\n",
              "  484,\n",
              "  486,\n",
              "  556,\n",
              "  570,\n",
              "  487,\n",
              "  541,\n",
              "  489,\n",
              "  789,\n",
              "  577,\n",
              "  614,\n",
              "  616,\n",
              "  723,\n",
              "  617,\n",
              "  635,\n",
              "  651,\n",
              "  665,\n",
              "  517,\n",
              "  533,\n",
              "  599,\n",
              "  767,\n",
              "  806,\n",
              "  807,\n",
              "  808,\n",
              "  809,\n",
              "  557,\n",
              "  559,\n",
              "  571,\n",
              "  629,\n",
              "  580,\n",
              "  598,\n",
              "  637,\n",
              "  719,\n",
              "  537,\n",
              "  578,\n",
              "  542,\n",
              "  560,\n",
              "  566,\n",
              "  791,\n",
              "  579,\n",
              "  768,\n",
              "  545,\n",
              "  662,\n",
              "  555,\n",
              "  588,\n",
              "  565,\n",
              "  567,\n",
              "  770,\n",
              "  792,\n",
              "  69,\n",
              "  77,\n",
              "  75,\n",
              "  103,\n",
              "  76,\n",
              "  265,\n",
              "  263,\n",
              "  418,\n",
              "  70,\n",
              "  74,\n",
              "  72,\n",
              "  104,\n",
              "  692,\n",
              "  71,\n",
              "  73,\n",
              "  231,\n",
              "  232,\n",
              "  78,\n",
              "  708,\n",
              "  99,\n",
              "  277,\n",
              "  236,\n",
              "  516,\n",
              "  241,\n",
              "  437,\n",
              "  280,\n",
              "  388,\n",
              "  299,\n",
              "  390,\n",
              "  79,\n",
              "  86,\n",
              "  95,\n",
              "  112,\n",
              "  81,\n",
              "  108,\n",
              "  98,\n",
              "  123,\n",
              "  100,\n",
              "  266,\n",
              "  101,\n",
              "  195,\n",
              "  132,\n",
              "  436,\n",
              "  174,\n",
              "  758,\n",
              "  229,\n",
              "  234,\n",
              "  298,\n",
              "  305,\n",
              "  249,\n",
              "  250,\n",
              "  276,\n",
              "  325,\n",
              "  281,\n",
              "  326,\n",
              "  342,\n",
              "  646,\n",
              "  311,\n",
              "  354,\n",
              "  358,\n",
              "  371,\n",
              "  4,\n",
              "  228,\n",
              "  18,\n",
              "  803,\n",
              "  66,\n",
              "  80,\n",
              "  230,\n",
              "  233,\n",
              "  6,\n",
              "  793,\n",
              "  65,\n",
              "  434,\n",
              "  205,\n",
              "  257,\n",
              "  269,\n",
              "  278,\n",
              "  67,\n",
              "  152,\n",
              "  84,\n",
              "  92,\n",
              "  261,\n",
              "  336,\n",
              "  320,\n",
              "  378,\n",
              "  135,\n",
              "  226,\n",
              "  374,\n",
              "  642,\n",
              "  262,\n",
              "  264,\n",
              "  337,\n",
              "  344,\n",
              "  63,\n",
              "  221,\n",
              "  515,\n",
              "  582,\n",
              "  182,\n",
              "  222,\n",
              "  673,\n",
              "  674,\n",
              "  134,\n",
              "  589,\n",
              "  627,\n",
              "  660,\n",
              "  258,\n",
              "  472,\n",
              "  480,\n",
              "  765,\n",
              "  407,\n",
              "  664,\n",
              "  416,\n",
              "  417,\n",
              "  712,\n",
              "  727,\n",
              "  720,\n",
              "  721,\n",
              "  413,\n",
              "  474,\n",
              "  666,\n",
              "  805,\n",
              "  420,\n",
              "  787,\n",
              "  463,\n",
              "  466,\n",
              "  5,\n",
              "  590,\n",
              "  355,\n",
              "  706,\n",
              "  46,\n",
              "  327,\n",
              "  375,\n",
              "  427,\n",
              "  160,\n",
              "  495,\n",
              "  172,\n",
              "  438,\n",
              "  186,\n",
              "  441,\n",
              "  620,\n",
              "  795,\n",
              "  126,\n",
              "  302,\n",
              "  303,\n",
              "  329,\n",
              "  158,\n",
              "  695,\n",
              "  700,\n",
              "  705,\n",
              "  300,\n",
              "  301,\n",
              "  328,\n",
              "  364,\n",
              "  592,\n",
              "  693,\n",
              "  753,\n",
              "  755,\n",
              "  129,\n",
              "  202,\n",
              "  203,\n",
              "  347,\n",
              "  190,\n",
              "  343,\n",
              "  192,\n",
              "  200,\n",
              "  208,\n",
              "  370,\n",
              "  504,\n",
              "  804,\n",
              "  332,\n",
              "  373,\n",
              "  501,\n",
              "  502,\n",
              "  243,\n",
              "  703,\n",
              "  273,\n",
              "  274,\n",
              "  252,\n",
              "  707,\n",
              "  254,\n",
              "  363,\n",
              "  251,\n",
              "  287,\n",
              "  308,\n",
              "  330,\n",
              "  284,\n",
              "  291,\n",
              "  289,\n",
              "  290,\n",
              "  83,\n",
              "  154,\n",
              "  508,\n",
              "  510,\n",
              "  91,\n",
              "  179,\n",
              "  105,\n",
              "  180,\n",
              "  85,\n",
              "  759,\n",
              "  119,\n",
              "  140,\n",
              "  110,\n",
              "  155,\n",
              "  509,\n",
              "  691,\n",
              "  89,\n",
              "  120,\n",
              "  114,\n",
              "  122,\n",
              "  97,\n",
              "  109,\n",
              "  138,\n",
              "  697,\n",
              "  102,\n",
              "  121,\n",
              "  118,\n",
              "  187,\n",
              "  111,\n",
              "  181,\n",
              "  141,\n",
              "  267,\n",
              "  87,\n",
              "  117,\n",
              "  93,\n",
              "  107,\n",
              "  94,\n",
              "  159,\n",
              "  106,\n",
              "  153,\n",
              "  136,\n",
              "  340,\n",
              "  194,\n",
              "  199,\n",
              "  201,\n",
              "  366,\n",
              "  386,\n",
              "  387,\n",
              "  88,\n",
              "  116,\n",
              "  690,\n",
              "  696,\n",
              "  96,\n",
              "  689,\n",
              "  113,\n",
              "  115,\n",
              "  137,\n",
              "  435,\n",
              "  760,\n",
              "  761],\n",
              " 1: [1,\n",
              "  237,\n",
              "  11,\n",
              "  62,\n",
              "  57,\n",
              "  58,\n",
              "  362,\n",
              "  396,\n",
              "  10,\n",
              "  782,\n",
              "  403,\n",
              "  654,\n",
              "  213,\n",
              "  739,\n",
              "  376,\n",
              "  680,\n",
              "  51,\n",
              "  756,\n",
              "  133,\n",
              "  596,\n",
              "  227,\n",
              "  338,\n",
              "  439,\n",
              "  445,\n",
              "  139,\n",
              "  507,\n",
              "  452,\n",
              "  514,\n",
              "  494,\n",
              "  503,\n",
              "  511,\n",
              "  648,\n",
              "  9,\n",
              "  746,\n",
              "  20,\n",
              "  27,\n",
              "  16,\n",
              "  361,\n",
              "  185,\n",
              "  443,\n",
              "  12,\n",
              "  239,\n",
              "  225,\n",
              "  245,\n",
              "  17,\n",
              "  802,\n",
              "  61,\n",
              "  411,\n",
              "  44,\n",
              "  491,\n",
              "  428,\n",
              "  655,\n",
              "  48,\n",
              "  583,\n",
              "  68,\n",
              "  729,\n",
              "  64,\n",
              "  224,\n",
              "  166,\n",
              "  471,\n",
              "  168,\n",
              "  446,\n",
              "  169,\n",
              "  220,\n",
              "  124,\n",
              "  268,\n",
              "  167,\n",
              "  394,\n",
              "  7,\n",
              "  238,\n",
              "  391,\n",
              "  467,\n",
              "  142,\n",
              "  622,\n",
              "  223,\n",
              "  794,\n",
              "  50,\n",
              "  183,\n",
              "  53,\n",
              "  125,\n",
              "  400,\n",
              "  676,\n",
              "  492,\n",
              "  730,\n",
              "  146,\n",
              "  214,\n",
              "  215,\n",
              "  774,\n",
              "  431,\n",
              "  469,\n",
              "  449,\n",
              "  450,\n",
              "  149,\n",
              "  444,\n",
              "  178,\n",
              "  512,\n",
              "  470,\n",
              "  602,\n",
              "  618,\n",
              "  652,\n",
              "  8,\n",
              "  733,\n",
              "  26,\n",
              "  31,\n",
              "  23,\n",
              "  165,\n",
              "  19,\n",
              "  150,\n",
              "  678,\n",
              "  737,\n",
              "  619,\n",
              "  658,\n",
              "  621,\n",
              "  745,\n",
              "  15,\n",
              "  468,\n",
              "  675,\n",
              "  731,\n",
              "  49,\n",
              "  52,\n",
              "  143,\n",
              "  736,\n",
              "  59,\n",
              "  219,\n",
              "  377,\n",
              "  749,\n",
              "  217,\n",
              "  497,\n",
              "  625,\n",
              "  797,\n",
              "  13,\n",
              "  14,\n",
              "  216,\n",
              "  656,\n",
              "  45,\n",
              "  148,\n",
              "  398,\n",
              "  688,\n",
              "  144,\n",
              "  672,\n",
              "  447,\n",
              "  453,\n",
              "  623,\n",
              "  796,\n",
              "  682,\n",
              "  683,\n",
              "  24,\n",
              "  679,\n",
              "  684,\n",
              "  685,\n",
              "  56,\n",
              "  432,\n",
              "  404,\n",
              "  775,\n",
              "  35,\n",
              "  397,\n",
              "  402,\n",
              "  454,\n",
              "  732,\n",
              "  734,\n",
              "  738,\n",
              "  742,\n",
              "  21,\n",
              "  455,\n",
              "  783,\n",
              "  798,\n",
              "  735,\n",
              "  744,\n",
              "  741,\n",
              "  748,\n",
              "  55,\n",
              "  442,\n",
              "  161,\n",
              "  212,\n",
              "  218,\n",
              "  624,\n",
              "  493,\n",
              "  747,\n",
              "  28,\n",
              "  38,\n",
              "  42,\n",
              "  405,\n",
              "  30,\n",
              "  406,\n",
              "  34,\n",
              "  687,\n",
              "  29,\n",
              "  496,\n",
              "  653,\n",
              "  657,\n",
              "  36,\n",
              "  498,\n",
              "  39,\n",
              "  184,\n",
              "  22,\n",
              "  701,\n",
              "  156,\n",
              "  513,\n",
              "  157,\n",
              "  500,\n",
              "  164,\n",
              "  800,\n",
              "  43,\n",
              "  147,\n",
              "  60,\n",
              "  430,\n",
              "  188,\n",
              "  399,\n",
              "  490,\n",
              "  728,\n",
              "  54,\n",
              "  750,\n",
              "  177,\n",
              "  584,\n",
              "  151,\n",
              "  259,\n",
              "  279,\n",
              "  349,\n",
              "  339,\n",
              "  457,\n",
              "  409,\n",
              "  462,\n",
              "  415,\n",
              "  458,\n",
              "  764,\n",
              "  772,\n",
              "  25,\n",
              "  395,\n",
              "  246,\n",
              "  677,\n",
              "  448,\n",
              "  801,\n",
              "  686,\n",
              "  781,\n",
              "  393,\n",
              "  499,\n",
              "  401,\n",
              "  659,\n",
              "  740,\n",
              "  776,\n",
              "  778,\n",
              "  779,\n",
              "  32,\n",
              "  41,\n",
              "  33,\n",
              "  681,\n",
              "  40,\n",
              "  162,\n",
              "  603,\n",
              "  799,\n",
              "  37,\n",
              "  440,\n",
              "  626,\n",
              "  780,\n",
              "  145,\n",
              "  163,\n",
              "  392,\n",
              "  743],\n",
              " 2: [],\n",
              " 3: [],\n",
              " 4: [],\n",
              " 5: [],\n",
              " 6: [],\n",
              " 7: [],\n",
              " 8: [],\n",
              " 9: [],\n",
              " 10: [],\n",
              " 11: [],\n",
              " 12: [],\n",
              " 13: [],\n",
              " 14: [],\n",
              " 15: [],\n",
              " 16: [],\n",
              " 17: [],\n",
              " 18: [],\n",
              " 19: [],\n",
              " 20: [],\n",
              " 21: [],\n",
              " 22: [],\n",
              " 23: [],\n",
              " 24: [],\n",
              " 25: [],\n",
              " 26: [],\n",
              " 27: [],\n",
              " 28: [],\n",
              " 29: [],\n",
              " 30: [],\n",
              " 31: [],\n",
              " 32: [],\n",
              " 33: [],\n",
              " 34: [],\n",
              " 35: [],\n",
              " 36: [],\n",
              " 37: [],\n",
              " 38: [],\n",
              " 39: [],\n",
              " 40: [],\n",
              " 41: [],\n",
              " 42: [],\n",
              " 43: [],\n",
              " 44: [],\n",
              " 45: [],\n",
              " 46: [],\n",
              " 47: [47,\n",
              "  196,\n",
              "  255,\n",
              "  306,\n",
              "  272,\n",
              "  353,\n",
              "  784,\n",
              "  786,\n",
              "  197,\n",
              "  647,\n",
              "  210,\n",
              "  645,\n",
              "  312,\n",
              "  352,\n",
              "  315,\n",
              "  345,\n",
              "  242,\n",
              "  421,\n",
              "  270,\n",
              "  282,\n",
              "  248,\n",
              "  702,\n",
              "  318,\n",
              "  360,\n",
              "  271,\n",
              "  351,\n",
              "  285,\n",
              "  295,\n",
              "  293,\n",
              "  331,\n",
              "  372,\n",
              "  643,\n",
              "  244,\n",
              "  292,\n",
              "  256,\n",
              "  296,\n",
              "  322,\n",
              "  591,\n",
              "  479,\n",
              "  751,\n",
              "  304,\n",
              "  316,\n",
              "  644,\n",
              "  698,\n",
              "  307,\n",
              "  314,\n",
              "  423,\n",
              "  425,\n",
              "  127,\n",
              "  206,\n",
              "  335,\n",
              "  379,\n",
              "  131,\n",
              "  365,\n",
              "  173,\n",
              "  356,\n",
              "  128,\n",
              "  175,\n",
              "  429,\n",
              "  694,\n",
              "  130,\n",
              "  319,\n",
              "  211,\n",
              "  426,\n",
              "  283,\n",
              "  367,\n",
              "  286,\n",
              "  288,\n",
              "  294,\n",
              "  310,\n",
              "  348,\n",
              "  383,\n",
              "  309,\n",
              "  317,\n",
              "  334,\n",
              "  368,\n",
              "  346,\n",
              "  369,\n",
              "  381,\n",
              "  382,\n",
              "  170,\n",
              "  424,\n",
              "  247,\n",
              "  593,\n",
              "  176,\n",
              "  785,\n",
              "  321,\n",
              "  324,\n",
              "  191,\n",
              "  757,\n",
              "  207,\n",
              "  313,\n",
              "  275,\n",
              "  384,\n",
              "  752,\n",
              "  754,\n",
              "  171,\n",
              "  193,\n",
              "  198,\n",
              "  350,\n",
              "  323,\n",
              "  380,\n",
              "  359,\n",
              "  385,\n",
              "  209,\n",
              "  333,\n",
              "  297,\n",
              "  357,\n",
              "  422,\n",
              "  704,\n",
              "  505,\n",
              "  506],\n",
              " 48: [],\n",
              " 49: [],\n",
              " 50: [],\n",
              " 51: [],\n",
              " 52: [],\n",
              " 53: [],\n",
              " 54: [],\n",
              " 55: [],\n",
              " 56: [],\n",
              " 57: [],\n",
              " 58: [],\n",
              " 59: [],\n",
              " 60: [],\n",
              " 61: [],\n",
              " 62: [],\n",
              " 63: [],\n",
              " 64: [],\n",
              " 65: [],\n",
              " 66: [],\n",
              " 67: [],\n",
              " 68: [],\n",
              " 69: [],\n",
              " 70: [],\n",
              " 71: [],\n",
              " 72: [],\n",
              " 73: [],\n",
              " 74: [],\n",
              " 75: [],\n",
              " 76: [],\n",
              " 77: [],\n",
              " 78: [],\n",
              " 79: [],\n",
              " 80: [],\n",
              " 81: [],\n",
              " 82: [],\n",
              " 83: [],\n",
              " 84: [],\n",
              " 85: [],\n",
              " 86: [],\n",
              " 87: [],\n",
              " 88: [],\n",
              " 89: [],\n",
              " 90: [],\n",
              " 91: [],\n",
              " 92: [],\n",
              " 93: [],\n",
              " 94: [],\n",
              " 95: [],\n",
              " 96: [],\n",
              " 97: [],\n",
              " 98: [],\n",
              " 99: [],\n",
              " 100: [],\n",
              " 101: [],\n",
              " 102: [],\n",
              " 103: [],\n",
              " 104: [],\n",
              " 105: [],\n",
              " 106: [],\n",
              " 107: [],\n",
              " 108: [],\n",
              " 109: [],\n",
              " 110: [],\n",
              " 111: [],\n",
              " 112: [],\n",
              " 113: [],\n",
              " 114: [],\n",
              " 115: [],\n",
              " 116: [],\n",
              " 117: [],\n",
              " 118: [],\n",
              " 119: [],\n",
              " 120: [],\n",
              " 121: [],\n",
              " 122: [],\n",
              " 123: [],\n",
              " 124: [],\n",
              " 125: [],\n",
              " 126: [],\n",
              " 127: [],\n",
              " 128: [],\n",
              " 129: [],\n",
              " 130: [],\n",
              " 131: [],\n",
              " 132: [],\n",
              " 133: [],\n",
              " 134: [],\n",
              " 135: [],\n",
              " 136: [],\n",
              " 137: [],\n",
              " 138: [],\n",
              " 139: [],\n",
              " 140: [],\n",
              " 141: [],\n",
              " 142: [],\n",
              " 143: [],\n",
              " 144: [],\n",
              " 145: [],\n",
              " 146: [],\n",
              " 147: [],\n",
              " 148: [],\n",
              " 149: [],\n",
              " 150: [],\n",
              " 151: [],\n",
              " 152: [],\n",
              " 153: [],\n",
              " 154: [],\n",
              " 155: [],\n",
              " 156: [],\n",
              " 157: [],\n",
              " 158: [],\n",
              " 159: [],\n",
              " 160: [],\n",
              " 161: [],\n",
              " 162: [],\n",
              " 163: [],\n",
              " 164: [],\n",
              " 165: [],\n",
              " 166: [],\n",
              " 167: [],\n",
              " 168: [],\n",
              " 169: [],\n",
              " 170: [],\n",
              " 171: [],\n",
              " 172: [],\n",
              " 173: [],\n",
              " 174: [],\n",
              " 175: [],\n",
              " 176: [],\n",
              " 177: [],\n",
              " 178: [],\n",
              " 179: [],\n",
              " 180: [],\n",
              " 181: [],\n",
              " 182: [],\n",
              " 183: [],\n",
              " 184: [],\n",
              " 185: [],\n",
              " 186: [],\n",
              " 187: [],\n",
              " 188: [],\n",
              " 189: [],\n",
              " 190: [],\n",
              " 191: [],\n",
              " 192: [],\n",
              " 193: [],\n",
              " 194: [],\n",
              " 195: [],\n",
              " 196: [],\n",
              " 197: [],\n",
              " 198: [],\n",
              " 199: [],\n",
              " 200: [],\n",
              " 201: [],\n",
              " 202: [],\n",
              " 203: [],\n",
              " 204: [],\n",
              " 205: [],\n",
              " 206: [],\n",
              " 207: [],\n",
              " 208: [],\n",
              " 209: [],\n",
              " 210: [],\n",
              " 211: [],\n",
              " 212: [],\n",
              " 213: [],\n",
              " 214: [],\n",
              " 215: [],\n",
              " 216: [],\n",
              " 217: [],\n",
              " 218: [],\n",
              " 219: [],\n",
              " 220: [],\n",
              " 221: [],\n",
              " 222: [],\n",
              " 223: [],\n",
              " 224: [],\n",
              " 225: [],\n",
              " 226: [],\n",
              " 227: [],\n",
              " 228: [],\n",
              " 229: [],\n",
              " 230: [],\n",
              " 231: [],\n",
              " 232: [],\n",
              " 233: [],\n",
              " 234: [],\n",
              " 235: [],\n",
              " 236: [],\n",
              " 237: [],\n",
              " 238: [],\n",
              " 239: [],\n",
              " 240: [],\n",
              " 241: [],\n",
              " 242: [],\n",
              " 243: [],\n",
              " 244: [],\n",
              " 245: [],\n",
              " 246: [],\n",
              " 247: [],\n",
              " 248: [],\n",
              " 249: [],\n",
              " 250: [],\n",
              " 251: [],\n",
              " 252: [],\n",
              " 253: [],\n",
              " 254: [],\n",
              " 255: [],\n",
              " 256: [],\n",
              " 257: [],\n",
              " 258: [],\n",
              " 259: [],\n",
              " 260: [],\n",
              " 261: [],\n",
              " 262: [],\n",
              " 263: [],\n",
              " 264: [],\n",
              " 265: [],\n",
              " 266: [],\n",
              " 267: [],\n",
              " 268: [],\n",
              " 269: [],\n",
              " 270: [],\n",
              " 271: [],\n",
              " 272: [],\n",
              " 273: [],\n",
              " 274: [],\n",
              " 275: [],\n",
              " 276: [],\n",
              " 277: [],\n",
              " 278: [],\n",
              " 279: [],\n",
              " 280: [],\n",
              " 281: [],\n",
              " 282: [],\n",
              " 283: [],\n",
              " 284: [],\n",
              " 285: [],\n",
              " 286: [],\n",
              " 287: [],\n",
              " 288: [],\n",
              " 289: [],\n",
              " 290: [],\n",
              " 291: [],\n",
              " 292: [],\n",
              " 293: [],\n",
              " 294: [],\n",
              " 295: [],\n",
              " 296: [],\n",
              " 297: [],\n",
              " 298: [],\n",
              " 299: [],\n",
              " 300: [],\n",
              " 301: [],\n",
              " 302: [],\n",
              " 303: [],\n",
              " 304: [],\n",
              " 305: [],\n",
              " 306: [],\n",
              " 307: [],\n",
              " 308: [],\n",
              " 309: [],\n",
              " 310: [],\n",
              " 311: [],\n",
              " 312: [],\n",
              " 313: [],\n",
              " 314: [],\n",
              " 315: [],\n",
              " 316: [],\n",
              " 317: [],\n",
              " 318: [],\n",
              " 319: [],\n",
              " 320: [],\n",
              " 321: [],\n",
              " 322: [],\n",
              " 323: [],\n",
              " 324: [],\n",
              " 325: [],\n",
              " 326: [],\n",
              " 327: [],\n",
              " 328: [],\n",
              " 329: [],\n",
              " 330: [],\n",
              " 331: [],\n",
              " 332: [],\n",
              " 333: [],\n",
              " 334: [],\n",
              " 335: [],\n",
              " 336: [],\n",
              " 337: [],\n",
              " 338: [],\n",
              " 339: [],\n",
              " 340: [],\n",
              " 341: [],\n",
              " 342: [],\n",
              " 343: [],\n",
              " 344: [],\n",
              " 345: [],\n",
              " 346: [],\n",
              " 347: [],\n",
              " 348: [],\n",
              " 349: [],\n",
              " 350: [],\n",
              " 351: [],\n",
              " 352: [],\n",
              " 353: [],\n",
              " 354: [],\n",
              " 355: [],\n",
              " 356: [],\n",
              " 357: [],\n",
              " 358: [],\n",
              " 359: [],\n",
              " 360: [],\n",
              " 361: [],\n",
              " 362: [],\n",
              " 363: [],\n",
              " 364: [],\n",
              " 365: [],\n",
              " 366: [],\n",
              " 367: [],\n",
              " 368: [],\n",
              " 369: [],\n",
              " 370: [],\n",
              " 371: [],\n",
              " 372: [],\n",
              " 373: [],\n",
              " 374: [],\n",
              " 375: [],\n",
              " 376: [],\n",
              " 377: [],\n",
              " 378: [],\n",
              " 379: [],\n",
              " 380: [],\n",
              " 381: [],\n",
              " 382: [],\n",
              " 383: [],\n",
              " 384: [],\n",
              " 385: [],\n",
              " 386: [],\n",
              " 387: [],\n",
              " 388: [],\n",
              " 389: [],\n",
              " 390: [],\n",
              " 391: [],\n",
              " 392: [],\n",
              " 393: [],\n",
              " 394: [],\n",
              " 395: [],\n",
              " 396: [],\n",
              " 397: [],\n",
              " 398: [],\n",
              " 399: [],\n",
              " 400: [],\n",
              " 401: [],\n",
              " 402: [],\n",
              " 403: [],\n",
              " 404: [],\n",
              " 405: [],\n",
              " 406: [],\n",
              " 407: [],\n",
              " 408: [408,\n",
              "  667,\n",
              "  419,\n",
              "  464,\n",
              "  608,\n",
              "  634,\n",
              "  610,\n",
              "  639,\n",
              "  414,\n",
              "  632,\n",
              "  460,\n",
              "  461,\n",
              "  574,\n",
              "  594,\n",
              "  769,\n",
              "  771,\n",
              "  488,\n",
              "  585,\n",
              "  631,\n",
              "  633,\n",
              "  522,\n",
              "  636,\n",
              "  640,\n",
              "  668,\n",
              "  540,\n",
              "  586,\n",
              "  546,\n",
              "  562,\n",
              "  572,\n",
              "  766,\n",
              "  710,\n",
              "  711,\n",
              "  410,\n",
              "  459,\n",
              "  451,\n",
              "  456,\n",
              "  412,\n",
              "  604,\n",
              "  465,\n",
              "  762,\n",
              "  520,\n",
              "  521,\n",
              "  601,\n",
              "  613,\n",
              "  523,\n",
              "  543,\n",
              "  600,\n",
              "  609,\n",
              "  525,\n",
              "  527,\n",
              "  722,\n",
              "  725,\n",
              "  534,\n",
              "  763,\n",
              "  535,\n",
              "  628,\n",
              "  552,\n",
              "  573,\n",
              "  553,\n",
              "  638,\n",
              "  671,\n",
              "  715,\n",
              "  709,\n",
              "  713,\n",
              "  473,\n",
              "  576,\n",
              "  524,\n",
              "  526,\n",
              "  530,\n",
              "  554,\n",
              "  539,\n",
              "  581,\n",
              "  482,\n",
              "  575,\n",
              "  615,\n",
              "  663,\n",
              "  649,\n",
              "  777,\n",
              "  669,\n",
              "  726,\n",
              "  475,\n",
              "  773,\n",
              "  670,\n",
              "  788,\n",
              "  548,\n",
              "  661,\n",
              "  549,\n",
              "  630,\n",
              "  606,\n",
              "  611,\n",
              "  607,\n",
              "  641,\n",
              "  716,\n",
              "  717,\n",
              "  718,\n",
              "  790,\n",
              "  476,\n",
              "  477,\n",
              "  550,\n",
              "  558,\n",
              "  547,\n",
              "  714,\n",
              "  587,\n",
              "  650,\n",
              "  518,\n",
              "  519,\n",
              "  529,\n",
              "  544,\n",
              "  532,\n",
              "  612,\n",
              "  538,\n",
              "  605,\n",
              "  478,\n",
              "  483,\n",
              "  485,\n",
              "  724,\n",
              "  481,\n",
              "  597,\n",
              "  563,\n",
              "  595,\n",
              "  528,\n",
              "  551,\n",
              "  531,\n",
              "  536,\n",
              "  561,\n",
              "  564,\n",
              "  568,\n",
              "  569],\n",
              " 409: [],\n",
              " 410: [],\n",
              " 411: [],\n",
              " 412: [],\n",
              " 413: [],\n",
              " 414: [],\n",
              " 415: [],\n",
              " 416: [],\n",
              " 417: [],\n",
              " 418: [],\n",
              " 419: [],\n",
              " 420: [],\n",
              " 421: [],\n",
              " 422: [],\n",
              " 423: [],\n",
              " 424: [],\n",
              " 425: [],\n",
              " 426: [],\n",
              " 427: [],\n",
              " 428: [],\n",
              " 429: [],\n",
              " 430: [],\n",
              " 431: [],\n",
              " 432: [],\n",
              " 433: [],\n",
              " 434: [],\n",
              " 435: [],\n",
              " 436: [],\n",
              " 437: [],\n",
              " 438: [],\n",
              " 439: [],\n",
              " 440: [],\n",
              " 441: [],\n",
              " 442: [],\n",
              " 443: [],\n",
              " 444: [],\n",
              " 445: [],\n",
              " 446: [],\n",
              " 447: [],\n",
              " 448: [],\n",
              " 449: [],\n",
              " 450: [],\n",
              " 451: [],\n",
              " 452: [],\n",
              " 453: [],\n",
              " 454: [],\n",
              " 455: [],\n",
              " 456: [],\n",
              " 457: [],\n",
              " 458: [],\n",
              " 459: [],\n",
              " 460: [],\n",
              " 461: [],\n",
              " 462: [],\n",
              " 463: [],\n",
              " 464: [],\n",
              " 465: [],\n",
              " 466: [],\n",
              " 467: [],\n",
              " 468: [],\n",
              " 469: [],\n",
              " 470: [],\n",
              " 471: [],\n",
              " 472: [],\n",
              " 473: [],\n",
              " 474: [],\n",
              " 475: [],\n",
              " 476: [],\n",
              " 477: [],\n",
              " 478: [],\n",
              " 479: [],\n",
              " 480: [],\n",
              " 481: [],\n",
              " 482: [],\n",
              " 483: [],\n",
              " 484: [],\n",
              " 485: [],\n",
              " 486: [],\n",
              " 487: [],\n",
              " 488: [],\n",
              " 489: [],\n",
              " 490: [],\n",
              " 491: [],\n",
              " 492: [],\n",
              " 493: [],\n",
              " 494: [],\n",
              " 495: [],\n",
              " 496: [],\n",
              " 497: [],\n",
              " 498: [],\n",
              " 499: [],\n",
              " 500: [],\n",
              " 501: [],\n",
              " 502: [],\n",
              " 503: [],\n",
              " 504: [],\n",
              " 505: [],\n",
              " 506: [],\n",
              " 507: [],\n",
              " 508: [],\n",
              " 509: [],\n",
              " 510: [],\n",
              " 511: [],\n",
              " 512: [],\n",
              " 513: [],\n",
              " 514: [],\n",
              " 515: [],\n",
              " 516: [],\n",
              " 517: [],\n",
              " 518: [],\n",
              " 519: [],\n",
              " 520: [],\n",
              " 521: [],\n",
              " 522: [],\n",
              " 523: [],\n",
              " 524: [],\n",
              " 525: [],\n",
              " 526: [],\n",
              " 527: [],\n",
              " 528: [],\n",
              " 529: [],\n",
              " 530: [],\n",
              " 531: [],\n",
              " 532: [],\n",
              " 533: [],\n",
              " 534: [],\n",
              " 535: [],\n",
              " 536: [],\n",
              " 537: [],\n",
              " 538: [],\n",
              " 539: [],\n",
              " 540: [],\n",
              " 541: [],\n",
              " 542: [],\n",
              " 543: [],\n",
              " 544: [],\n",
              " 545: [],\n",
              " 546: [],\n",
              " 547: [],\n",
              " 548: [],\n",
              " 549: [],\n",
              " 550: [],\n",
              " 551: [],\n",
              " 552: [],\n",
              " 553: [],\n",
              " 554: [],\n",
              " 555: [],\n",
              " 556: [],\n",
              " 557: [],\n",
              " 558: [],\n",
              " 559: [],\n",
              " 560: [],\n",
              " 561: [],\n",
              " 562: [],\n",
              " 563: [],\n",
              " 564: [],\n",
              " 565: [],\n",
              " 566: [],\n",
              " 567: [],\n",
              " 568: [],\n",
              " 569: [],\n",
              " 570: [],\n",
              " 571: [],\n",
              " 572: [],\n",
              " 573: [],\n",
              " 574: [],\n",
              " 575: [],\n",
              " 576: [],\n",
              " 577: [],\n",
              " 578: [],\n",
              " 579: [],\n",
              " 580: [],\n",
              " 581: [],\n",
              " 582: [],\n",
              " 583: [],\n",
              " 584: [],\n",
              " 585: [],\n",
              " 586: [],\n",
              " 587: [],\n",
              " 588: [],\n",
              " 589: [],\n",
              " 590: [],\n",
              " 591: [],\n",
              " 592: [],\n",
              " 593: [],\n",
              " 594: [],\n",
              " 595: [],\n",
              " 596: [],\n",
              " 597: [],\n",
              " 598: [],\n",
              " 599: [],\n",
              " 600: [],\n",
              " 601: [],\n",
              " 602: [],\n",
              " 603: [],\n",
              " 604: [],\n",
              " 605: [],\n",
              " 606: [],\n",
              " 607: [],\n",
              " 608: [],\n",
              " 609: [],\n",
              " 610: [],\n",
              " 611: [],\n",
              " 612: [],\n",
              " 613: [],\n",
              " 614: [],\n",
              " 615: [],\n",
              " 616: [],\n",
              " 617: [],\n",
              " 618: [],\n",
              " 619: [],\n",
              " 620: [],\n",
              " 621: [],\n",
              " 622: [],\n",
              " 623: [],\n",
              " 624: [],\n",
              " 625: [],\n",
              " 626: [],\n",
              " 627: [],\n",
              " 628: [],\n",
              " 629: [],\n",
              " 630: [],\n",
              " 631: [],\n",
              " 632: [],\n",
              " 633: [],\n",
              " 634: [],\n",
              " 635: [],\n",
              " 636: [],\n",
              " 637: [],\n",
              " 638: [],\n",
              " 639: [],\n",
              " 640: [],\n",
              " 641: [],\n",
              " 642: [],\n",
              " 643: [],\n",
              " 644: [],\n",
              " 645: [],\n",
              " 646: [],\n",
              " 647: [],\n",
              " 648: [],\n",
              " 649: [],\n",
              " 650: [],\n",
              " 651: [],\n",
              " 652: [],\n",
              " 653: [],\n",
              " 654: [],\n",
              " 655: [],\n",
              " 656: [],\n",
              " 657: [],\n",
              " 658: [],\n",
              " 659: [],\n",
              " 660: [],\n",
              " 661: [],\n",
              " 662: [],\n",
              " 663: [],\n",
              " 664: [],\n",
              " 665: [],\n",
              " 666: [],\n",
              " 667: [],\n",
              " 668: [],\n",
              " 669: [],\n",
              " 670: [],\n",
              " 671: [],\n",
              " 672: [],\n",
              " 673: [],\n",
              " 674: [],\n",
              " 675: [],\n",
              " 676: [],\n",
              " 677: [],\n",
              " 678: [],\n",
              " 679: [],\n",
              " 680: [],\n",
              " 681: [],\n",
              " 682: [],\n",
              " 683: [],\n",
              " 684: [],\n",
              " 685: [],\n",
              " 686: [],\n",
              " 687: [],\n",
              " 688: [],\n",
              " 689: [],\n",
              " 690: [],\n",
              " 691: [],\n",
              " 692: [],\n",
              " 693: [],\n",
              " 694: [],\n",
              " 695: [],\n",
              " 696: [],\n",
              " 697: [],\n",
              " 698: [],\n",
              " 699: [],\n",
              " 700: [],\n",
              " 701: [],\n",
              " 702: [],\n",
              " 703: [],\n",
              " 704: [],\n",
              " 705: [],\n",
              " 706: [],\n",
              " 707: [],\n",
              " 708: [],\n",
              " 709: [],\n",
              " 710: [],\n",
              " 711: [],\n",
              " 712: [],\n",
              " 713: [],\n",
              " 714: [],\n",
              " 715: [],\n",
              " 716: [],\n",
              " 717: [],\n",
              " 718: [],\n",
              " 719: [],\n",
              " 720: [],\n",
              " 721: [],\n",
              " 722: [],\n",
              " 723: [],\n",
              " 724: [],\n",
              " 725: [],\n",
              " 726: [],\n",
              " 727: [],\n",
              " 728: [],\n",
              " 729: [],\n",
              " 730: [],\n",
              " 731: [],\n",
              " 732: [],\n",
              " 733: [],\n",
              " 734: [],\n",
              " 735: [],\n",
              " 736: [],\n",
              " 737: [],\n",
              " 738: [],\n",
              " 739: [],\n",
              " 740: [],\n",
              " 741: [],\n",
              " 742: [],\n",
              " 743: [],\n",
              " 744: [],\n",
              " 745: [],\n",
              " 746: [],\n",
              " 747: [],\n",
              " 748: [],\n",
              " 749: [],\n",
              " 750: [],\n",
              " 751: [],\n",
              " 752: [],\n",
              " 753: [],\n",
              " 754: [],\n",
              " 755: [],\n",
              " 756: [],\n",
              " 757: [],\n",
              " 758: [],\n",
              " 759: [],\n",
              " 760: [],\n",
              " 761: [],\n",
              " 762: [],\n",
              " 763: [],\n",
              " 764: [],\n",
              " 765: [],\n",
              " 766: [],\n",
              " 767: [],\n",
              " 768: [],\n",
              " 769: [],\n",
              " 770: [],\n",
              " 771: [],\n",
              " 772: [],\n",
              " 773: [],\n",
              " 774: [],\n",
              " 775: [],\n",
              " 776: [],\n",
              " 777: [],\n",
              " 778: [],\n",
              " 779: [],\n",
              " 780: [],\n",
              " 781: [],\n",
              " 782: [],\n",
              " 783: [],\n",
              " 784: [],\n",
              " 785: [],\n",
              " 786: [],\n",
              " 787: [],\n",
              " 788: [],\n",
              " 789: [],\n",
              " 790: [],\n",
              " 791: [],\n",
              " 792: [],\n",
              " 793: [],\n",
              " 794: [],\n",
              " 795: [],\n",
              " 796: [],\n",
              " 797: [],\n",
              " 798: [],\n",
              " 799: [],\n",
              " 800: [],\n",
              " 801: [],\n",
              " 802: [],\n",
              " 803: [],\n",
              " 804: [],\n",
              " 805: [],\n",
              " 806: [],\n",
              " 807: [],\n",
              " 808: [],\n",
              " 809: [],\n",
              " 810: [],\n",
              " 811: []}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YRS1Fh6o8w-l",
        "outputId": "f534183d-eeba-4cc7-f25c-2292f33df93f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 249
        }
      },
      "source": [
        "# Start Prob [1,0,0,0] or [0.25]*4\n",
        "#transistion prob [0.25]\n",
        "from hmmlearn import hmm\n",
        "\n",
        "clstrs = []\n",
        "for i in range(N):\n",
        "  if len(ClusterMapping[i]) !=0:\n",
        "    clstrs.append(ClusterMapping[i]);\n",
        "\n",
        "clstr_seq = np.ones((N,))*-1\n",
        "# --------------------------------------------------------------------------\n",
        "start_prob=np.ones((4,))/4.0\n",
        "# --------------------------------------------------------------------------\n",
        "id = 0;\n",
        "max_clstr = 0\n",
        "for clstr in clstrs:\n",
        "  id+=1\n",
        "  if len(clstr)>max_clstr:\n",
        "    max_clstr = len(clstr)\n",
        "hmm_wts = np.zeros((4,max_clstr)).astype('float')\n",
        "hmm_means = np.zeros((4,max_clstr,mfcc_feat.shape[-1]))\n",
        "hmm_covar = np.zeros((4,max_clstr,mfcc_feat.shape[-1],mfcc_feat.shape[-1]))\n",
        "\n",
        "id=-1\n",
        "for clstr in clstrs:\n",
        "  id+=1\n",
        "  clstr_wt = 1.0/len(clstr)\n",
        "  inclstr_id=0\n",
        "  for seg in clstr:\n",
        "    clstr_seq[inclstr_id]=id\n",
        "    hmm_wts[id][inclstr_id]=clstr_wt\n",
        "    hmm_means[id][inclstr_id]=GaussianMeans[seg]\n",
        "    hmm_covar[id][inclstr_id]=GaussianCovMatrices[seg]\n",
        "    inclstr_id+=1\n",
        "\n",
        "trans_prob = np.zeros((4,4))\n",
        "# --------------------------------------------------------------------------\n",
        "clstr_seq = clstr_seq.astype(np.int)\n",
        "for i in range(1,N):\n",
        "  trans_prob[clstr_seq[i-1]][clstr_seq[i]]+=1\n",
        "trans_prob = np.divide(trans_prob.astype('float'),np.sum(trans_prob,axis=1))\n",
        "# --------------------------------------------------------------------------\n",
        "U_GMM_HMM =  hmm.GMMHMM(n_components =4,\n",
        "                                 n_mix =N,\n",
        "                                 startprob_prior = start_prob,\n",
        "                                 transmat_prior  = trans_prob,\n",
        "                                 weights_prior  =hmm_wts ,\n",
        "                                 means_weight  = hmm_means,\n",
        "                                 covars_weight  = hmm_covar\n",
        "                                 )\n",
        "print(\" Shape :  start_prob \",start_prob.shape)\n",
        "print(\" Shape :  trans_prob \",trans_prob.shape)\n",
        "print(\" Shape :  hmm_wts \",hmm_wts.shape)\n",
        "print(\" Shape :  hmm_means \",hmm_means.shape)\n",
        "print(\" Shape :  hmm_covar \",hmm_covar.shape)\n",
        "print(\" Shape :  mfcc_feat \",mfcc_feat.shape)\n",
        "aligned_lbls = U_GMM_HMM.fit(mfcc_feat)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-37-53e1c90cdbd4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mclstr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mclstrs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m   \u001b[0mid\u001b[0m\u001b[0;34m+=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m   \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m     \u001b[0mmax_clstr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0mhmm_wts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmax_clstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'float'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: '>' not supported between instances of 'int' and 'builtin_function_or_method'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aSR5s72TX2u0"
      },
      "source": [
        "p.pop(1)\n",
        "p.pop(3-1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ts618y0lX5yO"
      },
      "source": [
        "p"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i63Ltu_sYS-d"
      },
      "source": [
        "p.insert(1, 13)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dySuLF0rYj7z"
      },
      "source": [
        "d = dict(zip(range(10),[[i] for i in range(10)]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JQqH5QGnYkrf"
      },
      "source": [
        "d[0].append(2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IYqg3drNaCZA"
      },
      "source": [
        "d"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qoB9F6qOaM49"
      },
      "source": [
        "from scipy.stats import norm"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AfO6w38_ejRu",
        "outputId": "505d8f18-593d-4e87-abd7-da650ff56657",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 303
        }
      },
      "source": [
        "m,c = norm.fit(mfcc_feat[0:100],d=19)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-58-f88d49c2ed43>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnorm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmfcc_feat\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m19\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/scipy/stats/_continuous_distns.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, data, **kwds)\u001b[0m\n\u001b[1;32m    274\u001b[0m         \u001b[0mfscale\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'fscale'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    275\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 276\u001b[0;31m         \u001b[0m_remove_optimizer_parameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    277\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    278\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfloc\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfscale\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/scipy/stats/_continuous_distns.py\u001b[0m in \u001b[0;36m_remove_optimizer_parameters\u001b[0;34m(kwds)\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'optimizer'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Unknown arguments: %s.\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: Unknown arguments: {'d': 19}."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eWXWVGYMek4I"
      },
      "source": [
        "data = norm.rvs(loc=0,scale=2,size=10, )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q9U34Y1Oev_N",
        "outputId": "c5ad572d-c11d-4b53-b1c2-17f82d02473b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "c.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "()"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ifcW5chPexmQ",
        "outputId": "36329120-79db-44f0-ef54-725bc701cc39",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "mfcc_feat[0:100].shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(100, 19)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pfc3qtegfQOX"
      },
      "source": [
        "m = np.mean(mfcc_feat[0:100], axis = 0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mNC7qDvkfS4H"
      },
      "source": [
        "c = np.cov(mfcc_feat[0:100].T)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xvdwNlt7g8BZ",
        "outputId": "fe85bb38-0e12-4f39-c327-598da1ab484b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "m.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(19,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 107
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Mu4QPnphscO",
        "outputId": "7ecca6a5-aa41-4c64-9321-2c352032ed71",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "a = 1\n",
        "a +=2\n",
        "a"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BbPJg1nKAfW9"
      },
      "source": [
        "a = [[-10,-3,4], [4,-104,-500]]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QB7labgaKHKZ"
      },
      "source": [
        "i, j = np.argwhere(a == np.min(a)).ravel()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rIUkeqDCSAwZ"
      },
      "source": [
        "a = [1,2,3] + [3,4,5]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hEBNetzTZscl"
      },
      "source": [
        "a[0] = [9 for i in a[0]]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i4GEiihwadYA",
        "outputId": "07895ee0-102e-403b-89c2-093f60089957",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "a"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[9, 9, 9], [4, -104, -500]]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 188
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C5aXQx8OfGAI",
        "outputId": "f35e680e-2e97-4129-d8e2-aeaeb3a0cc9b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 316
        }
      },
      "source": [
        "import hmmlearn"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-036832e0c673>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mhmmlearn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'hmmlearn'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "deGGkkZOp7Wx"
      },
      "source": [
        "d"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eLmtU8On9EdS"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}